{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "600e154c",
        "execution_start": 1744216131598,
        "execution_millis": 3920,
        "execution_context_id": "eef486c5-14b7-4560-ae68-60b6c0622fdc",
        "cell_id": "051f8377b8c247a4941c80e87efdd609",
        "deepnote_cell_type": "code"
      },
      "source": "from Moduled_functions import get_data\nfrom Moduled_functions import tranformation\nfrom Moduled_functions import calculate_ema_slope\nfrom Moduled_functions import place_order\nfrom m_email import send_email\nimport pandas as pd\nfrom keras.models import load_model\nfrom sklearn.preprocessing import StandardScaler\nimport schedule\nimport time\nfrom datetime import datetime\nimport os\naccess_token = os.environ[\"ACCESS_TOKEN\"]\n\nbearish_model = load_model('/work/Trained_Models/FX_Bearish_model_2025-02-19.keras')\nbullish_model = load_model('/work/Trained_Models/FX_Bullish_model_2025-02-21.keras')",
      "block_group": "e011e7f7e67449c1b21244e5d1d0acb8",
      "execution_count": 1,
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-04-09 16:28:52.423554: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2025-04-09 16:28:52.427284: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-04-09 16:28:52.458456: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-04-09 16:28:52.458583: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-09 16:28:52.459419: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-04-09 16:28:52.464488: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-04-09 16:28:52.465284: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-04-09 16:28:53.326277: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "c4a0e5a6",
        "is_code_hidden": true,
        "execution_start": 1743981602235,
        "execution_millis": 344,
        "is_output_hidden": true,
        "execution_context_id": "877e3c38-7686-489a-933d-a9bb8bf843fc",
        "deepnote_app_is_code_hidden": true,
        "deepnote_app_is_output_hidden": true,
        "cell_id": "00f21d7de5bc487fb721a1659115a7bc",
        "deepnote_cell_type": "code"
      },
      "source": "import os\n\n# Create directory structure\ndef create_directory_structure():\n    directories = [\n        'data',\n        'data/raw',\n        'data/processed',\n        'data/signals',\n        'data/orders',\n        'data/predictions',\n        'logs',\n        'config'\n    ]\n    \n    for directory in directories:\n        os.makedirs(directory, exist_ok=True)\n        print(f\"Created directory: {directory}\")\n\ncreate_directory_structure()",
      "block_group": "00f21d7de5bc487fb721a1659115a7bc",
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "text": "Created directory: data\nCreated directory: data/raw\nCreated directory: data/processed\nCreated directory: data/signals\nCreated directory: data/orders\nCreated directory: data/predictions\nCreated directory: logs\nCreated directory: config\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "f2248899",
        "is_code_hidden": false,
        "execution_start": 1744216135565,
        "execution_millis": 137,
        "execution_context_id": "eef486c5-14b7-4560-ae68-60b6c0622fdc",
        "deepnote_app_is_code_hidden": true,
        "cell_id": "adb1ed85b389463e88051db3f863e8a1",
        "deepnote_cell_type": "code"
      },
      "source": "# Combined trading system framework\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport requests\nfrom abc import ABC, abstractmethod\nimport logging\nimport json\nfrom Moduled_functions import get_data\n\n# Configure logging\nlogging.basicConfig(\n    filename='logs/trading_system.log',\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger('TradingSystem')\nclass BaseStrategy(ABC):\n    def __init__(self, name):\n        self.name = name\n        self.signals_path = f'data/signals/signals_{name}.csv'\n        self.trades_path = f'data/orders/trades_{name}.csv'\n        self.config_path = f'config/strategy_{name}.json'\n        self.load_config()\n    \n    def load_config(self):\n        \"\"\"Load strategy configuration\"\"\"\n        try:\n            with open(self.config_path, 'r') as f:\n                self.config = json.load(f)\n        except FileNotFoundError:\n            self.config = self.get_default_config()\n            self.save_config()\n    \n    def save_config(self):\n        \"\"\"Save strategy configuration\"\"\"\n        with open(self.config_path, 'w') as f:\n            json.dump(self.config, f, indent=4)\n    \n    @abstractmethod\n    def get_default_config(self):\n        \"\"\"Get default strategy configuration\"\"\"\n        pass\n    \n    @abstractmethod\n    def generate_signals(self, data):\n        \"\"\"Generate trading signals based on strategy logic\"\"\"\n        pass\n    \n    @abstractmethod\n    def get_order_parameters(self, current_price, signal):\n        \"\"\"Get order parameters based on strategy signal\"\"\"\n        pass\n    \n    def save_signals(self, signals_data):\n        \"\"\"Save strategy signals to history\"\"\"\n        try:\n            if os.path.exists(self.signals_path):\n                existing_signals = pd.read_csv(self.signals_path)\n                signals_data = signals_data.iloc[-1:]\n                updated_signals = pd.concat([existing_signals, signals_data])\n            else:\n                updated_signals = signals_data\n            updated_signals.to_csv(self.signals_path, index=False)\n            logger.info(f\"Signals saved for strategy {self.name}\")\n        except Exception as e:\n            logger.error(f\"Error saving signals for strategy {self.name}: {str(e)}\")\n    \n    def save_trade(self, trade_data):\n        \"\"\"Save trade details to history\"\"\"\n        try:\n            if os.path.exists(self.trades_path):\n                existing_trades = pd.read_csv(self.trades_path)\n                updated_trades = pd.concat([existing_trades, trade_data])\n            else:\n                updated_trades = trade_data\n            updated_trades.to_csv(self.trades_path, index=False)\n            logger.info(f\"Trade saved for strategy {self.name}\")\n        except Exception as e:\n            logger.error(f\"Error saving trade for strategy {self.name}: {str(e)}\")\n\nclass StrategyRegistry:\n    _strategies = {}\n    \n    @classmethod\n    def register(cls, strategy_instance):\n        \"\"\"Register a new strategy\"\"\"\n        cls._strategies[strategy_instance.name] = strategy_instance\n        logger.info(f\"Strategy registered: {strategy_instance.name}\")\n    \n    @classmethod\n    def get_strategy(cls, name):\n        \"\"\"Get a registered strategy by name\"\"\"\n        return cls._strategies.get(name)\n    \n    @classmethod\n    def get_all_strategies(cls):\n        \"\"\"Get all registered strategies\"\"\"\n        return cls._strategies",
      "block_group": "d004a156fdd64a0a98947cf34419eae7",
      "execution_count": 2,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "ade30329",
        "is_code_hidden": true,
        "execution_start": 1744216135972,
        "execution_millis": 2,
        "execution_context_id": "eef486c5-14b7-4560-ae68-60b6c0622fdc",
        "deepnote_app_is_code_hidden": true,
        "cell_id": "504fb6ab52404f93a5301b732be9f788",
        "deepnote_cell_type": "code"
      },
      "source": "class DataHandler:\n    def __init__(self):\n        self.scaler = None\n        self.raw_data_path = 'data/raw/base_data.csv'\n        self.processed_data_path = 'data/processed/transformed_data.csv'\n    \n    def get_and_prepare_data(self, lookback, access_token):\n        from Moduled_functions import tranformation\n        \"\"\"Get and prepare the base data\"\"\"\n        try:\n            base_data, current_price = get_data(lookback, access_token)\n            #base_data_append=base_data.iloc[-1:]\n\n        # Read existing history\n            try:\n                existing_data = pd.read_csv(self.raw_data_path)\n                existing_data['datetime'] = pd.to_datetime(existing_data['datetime'])\n                base_data['datetime'] = pd.to_datetime(base_data['datetime'])\n                \n                \n                # Add new records\n                new_records = base_data[~base_data['datetime'].isin(existing_data['datetime'])]\n                if not new_records.empty:\n                    updated_data = pd.concat([existing_data, new_records])\n                    updated_data = updated_data.sort_values('datetime')\n                else:\n                    updated_data = existing_data\n            except FileNotFoundError:\n                updated_data = base_data\n\n            updated_data.to_csv(self.raw_data_path, index=False)\n            logger.info(f\"Raw data saved to {self.raw_data_path}\")\n            \n            base_data = tranformation(base_data, 0.0015)            \n            return base_data, current_price\n        except Exception as e:\n            logger.error(f\"Error in get_and_prepare_data: {str(e)}\")\n            raise\n    \n    def calculate_technical_indicators(self, data):\n        \"\"\"Calculate technical indicators\"\"\"\n        try:\n            data['EMA_slope'] = calculate_ema_slope(data, 'Open', 9)\n            data['EMA_slope_15'] = calculate_ema_slope(data, 'Open', 15)\n            data['EMA_slope_60'] = calculate_ema_slope(data, 'Open', 60)\n            data['deviation_'] = data['bullish_move_flag_20'] + data['bearish_move_flag_20']\n            \n            try:\n                # Read existing history\n                existing_data = pd.read_csv(self.processed_data_path)\n                existing_data['datetime'] = pd.to_datetime(existing_data['datetime'])\n                data['datetime'] = pd.to_datetime(data['datetime'])\n                # Add new records\n                new_records = data[~data['datetime'].isin(existing_data['datetime'])]\n                if not new_records.empty:\n                    data = pd.concat([existing_data, new_records])\n                    data = data.sort_values('datetime')\n                else:\n                    data = existing_data\n            except FileNotFoundError:\n                data.to_csv(self.processed_data_path, index=False)\n\n            data.to_csv(self.processed_data_path, index=False)\n\n            logger.info(f\"Processed data saved to {self.processed_data_path}\")\n            return data\n        except Exception as e:\n            logger.error(f\"Error in calculate_technical_indicators: {str(e)}\")\n            raise\n    \n    def normalize_features(self, data):\n        \"\"\"Normalize the feature data\"\"\"\n        try:\n            X = data.iloc[:,9:69]\n            y = data['deviation_']\n            \n            if self.scaler is None:\n                self.scaler = StandardScaler()\n                self.scaler.fit(X)\n            \n            X_normalized = pd.DataFrame(self.scaler.transform(X)).round(1)\n            return X_normalized, y\n        except Exception as e:\n            logger.error(f\"Error in normalize_features: {str(e)}\")\n            raise\nclass OrderManager:\n    def __init__(self, access_token):\n        self.access_token = access_token\n        #self.account_id = account_id\n        self.orders_path = 'data/orders/all_orders.csv'\n    \n    def place_order(self, current_price, stop_loss, take_profit, quantity,account_id):\n        \"\"\"Place an order\"\"\"\n        try:\n            order = place_order(\n                str(current_price),\n                str(round(stop_loss, 5)),\n                str(round(take_profit, 5)),\n                quantity,\n                self.access_token,\n                account_id\n            )\n            logger.info(f\"Order placed: {order['orderCreateTransaction'].get('id')}\")\n            return order\n        except Exception as e:\n            logger.error(f\"Error placing order: {str(e)}\")\n            raise\n    \n    def save_order(self, order_data):\n        \"\"\"Save order details to history\"\"\"\n        try:\n            if os.path.exists(self.orders_path):\n                existing_orders = pd.read_csv(self.orders_path)\n                updated_orders = pd.concat([existing_orders, order_data])\n            else:\n                updated_orders = order_data\n            updated_orders.to_csv(self.orders_path, index=False)\n            logger.info(\"Order saved to history\")\n        except Exception as e:\n            logger.error(f\"Error saving order: {str(e)}\")",
      "block_group": "98e7de400ce44087bb93324ee96e7f8e",
      "execution_count": 4,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "94a32eef",
        "is_code_hidden": true,
        "execution_start": 1744216138150,
        "execution_millis": 3,
        "execution_context_id": "eef486c5-14b7-4560-ae68-60b6c0622fdc",
        "deepnote_app_is_code_hidden": true,
        "cell_id": "eb4c0d0fba4740ee82a9e6bcc4475405",
        "deepnote_cell_type": "code"
      },
      "source": "# Let's modify the TradingSystem class to properly merge the prediction data with the base data\nclass TradingSystem:\n    def __init__(self, access_token, bearish_model, bullish_model):\n        self.data_handler = DataHandler()\n        self.order_manager = OrderManager(access_token)\n        self.predictions_data_path = 'data/predictions/predictions_data.csv'\n        \n    def execute(self, lookback=100):\n        try:\n            # Get and prepare data\n            base_data, current_price = self.data_handler.get_and_prepare_data(lookback, self.order_manager.access_token)\n            base_data = self.data_handler.calculate_technical_indicators(base_data)\n            X_normalized, y = self.data_handler.normalize_features(base_data)\n            \n            # Generate predictions\n            y_pred_bearish = bearish_model.predict(X_normalized, verbose=0)\n            y_pred_bullish = bullish_model.predict(X_normalized, verbose=0)\n\n            # Ensure datetime is unique before combining results\n            base_data = base_data.drop_duplicates(subset='datetime').reset_index(drop=True)\n            \n            # Combine results with datetime from base_data\n            result_combined = pd.concat([\n                base_data['datetime'].reset_index(drop=True),\n                pd.DataFrame(y_pred_bearish, columns=['bearish_0', 'bearish_1', 'bearish_2', 'bearish_3']),\n                pd.DataFrame(y_pred_bullish, columns=['bullish_0', 'bullish_1', 'bullish_2', 'bullish_3'])\n            ], axis=1)\n            \n            try:\n                # Read existing predictions history\n                existing_preds = pd.read_csv(self.predictions_data_path)\n                existing_preds['datetime'] = pd.to_datetime(existing_preds['datetime'])\n                result_combined['datetime'] = pd.to_datetime(result_combined['datetime'])\n                \n                # Add new predictions\n                new_preds = result_combined[~result_combined['datetime'].isin(existing_preds['datetime'])]\n                if not new_preds.empty:\n                    updated_preds = pd.concat([existing_preds, new_preds])\n                    updated_preds = updated_preds.sort_values('datetime').reset_index(drop=True)\n                else:\n                    updated_preds = existing_preds\n            except FileNotFoundError:\n                updated_preds = result_combined\n            \n            updated_preds.to_csv(self.predictions_data_path, index=False)\n            logger.info(f\"Raw data saved to {self.predictions_data_path}\")\n            # Merge predictions with base data\n            base_data['datetime'] = pd.to_datetime(base_data['datetime'])\n            data_with_predictions = pd.merge(\n                base_data.drop_duplicates(subset='datetime'),\n                updated_preds,\n                on='datetime',\n                how='inner'\n            )\n            \n            # Process each strategy\n            for strategy in StrategyRegistry.get_all_strategies().values():\n                self._process_strategy(strategy, data_with_predictions, current_price)\n            \n            logger.info(f\"Execution completed at {datetime.now()}\")\n            \n        except Exception as e:\n            logger.error(f\"Error in execute: {str(e)}\")\n            raise\n    \n    def _process_strategy(self, strategy, data, current_price):\n        try:\n            # Generate signals\n            signals = strategy.generate_signals(data)\n            signals['timestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n            strategy.save_signals(signals)\n            \n            # Check signals and execute trades\n            if not signals.empty:\n                latest_bearish = signals['bearish_flag'].iloc[-1]\n                latest_bullish = signals['bullish_flag'].iloc[-1]\n                \n                if latest_bullish == 1 and latest_bearish != 2:\n                    self._execute_trade(strategy, 1, current_price)\n                elif latest_bearish == 2 and latest_bullish != 1:\n                    self._execute_trade(strategy, 2, current_price)\n                    \n        except Exception as e:\n            logger.error(f\"Error processing strategy {strategy.name}: {str(e)}\")\n    \n    def _execute_trade(self, strategy, signal, current_price):\n        try:\n            order_params = strategy.get_order_parameters(current_price, signal)\n            if not order_params:\n                return\n            \n            order = self.order_manager.place_order(\n                current_price,\n                order_params['stop_loss'],\n                order_params['take_profit'],\n                order_params['quantity'],\n                order_params['account_id']\n            )\n            \n            order_id = order['orderCreateTransaction'].get('id')\n            order_time = order['orderCreateTransaction'].get('time')\n            account_id = order['orderCreateTransaction'].get('accountID')\n            \n            # Save trade details\n            trade_data = pd.DataFrame({\n                'Time': [order_time],\n                'Strategy': [strategy.name],\n                'Type': [order_params['type']],\n                'Quantity': [order_params['quantity']],\n                'Price': [current_price],\n                'Take_Profit': [order_params['take_profit']],\n                'Stop_Loss': [order_params['stop_loss']],\n                'Order_ID': [order_id],\n                'Account_ID': [account_id],\n            })\n            \n            strategy.save_trade(trade_data)\n            self.order_manager.save_order(trade_data)\n            \n            # Send notification\n            message = f\"{strategy.name} {order_params['type']} Order placed with order no: {order_id}\"\n            #requests.get(f'https://api.day.app/iFbt9PqBdm6d2YvUT4irnN/{order_params[\"type\"]} Order Placed/{message}')\n            logger.info(message)\n            \n        except Exception as e:\n            logger.error(f\"Error executing trade for strategy {strategy.name}: {str(e)}\")\n\nprint(\"Trading system framework initialized with directory structure\")",
      "block_group": "dc265a2ae0a043018ce77028bce37b98",
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "text": "Trading system framework initialized with directory structure\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "7ff61d7e",
        "is_code_hidden": false,
        "execution_start": 1744216140363,
        "execution_millis": 2,
        "execution_context_id": "eef486c5-14b7-4560-ae68-60b6c0622fdc",
        "deepnote_app_is_code_hidden": true,
        "cell_id": "8e1f6e96a5094d3992fb9e5d9fa5839b",
        "deepnote_cell_type": "code"
      },
      "source": "# Add the missing get_order_parameters method to all strategy classes\nclass VolumeBasedStrategy(BaseStrategy):\n    def __init__(self):\n        super().__init__('volume_based')\n    \n    def get_default_config(self):\n        return {\n            'ema_slope_threshold': 450,\n            'ema_slope_15_threshold_max': 750,\n            'ema_slope_15_threshold_min': -750,\n            'ema_slope_60_threshold': 0.50,\n            'bearish_threshold_min': 0.5,\n            'bearish_threshold_max': 0.65,\n            'volume_threshold': 500,\n            'take_profit_multiplier': 1.0015,\n            'stop_loss_multiplier': 0.0005,\n            'quantity': '1000000',\n            'account_id': account_id\n        }\n    \n    def generate_signals(self, data):\n        config = self.config\n        \n        bearish_signals = data.apply(lambda x: 2 if (\n            x['bearish_2'] > config['bearish_threshold_min'] and\n            (x['EMA_slope_15'] > config['ema_slope_15_threshold_max'] or\n             x['EMA_slope_15'] < config['ema_slope_15_threshold_min']) and\n            x['volume'] > config['volume_threshold']\n        ) else 0, axis=1)\n\n        bullish_signals = data.apply(lambda x: 1 if (\n            x['bullish_1'] > config['bearish_threshold_min'] and\n            (x['EMA_slope_15'] > config['ema_slope_15_threshold_max'] or\n             x['EMA_slope_15'] < config['ema_slope_15_threshold_min']) and\n            x['volume'] > config['volume_threshold']\n        ) else 0, axis=1)\n        \n        signals = pd.DataFrame({\n            'datetime': data['datetime'],\n            'bearish_flag': bearish_signals,\n            'bullish_flag': bullish_signals\n        })\n        \n        return signals\n    \n    def get_order_parameters(self, current_price, signal):\n        config = self.config\n        \n        if signal == 1:  # Bullish\n            return {\n                'take_profit': current_price * (1+config['take_profit_multiplier']),\n                'stop_loss': config['stop_loss_multiplier'],\n                'quantity': config['quantity'],\n                'type': 'BUY',\n                'account_id': config['account_id']\n            }\n        elif signal == 2:  # Bearish\n            return {\n                'take_profit': current_price * (1 - config['take_profit_multiplier']),\n                'stop_loss': config['stop_loss_multiplier'],\n                'quantity': f\"-{config['quantity']}\",\n                'type': 'SELL',\n                'account_id': config['account_id']\n            }\n        return None\n\nclass VolumeBasedStrategyHedge(BaseStrategy):\n    def __init__(self):\n        super().__init__('volume_based_hedge')\n    \n    def get_default_config(self):\n        return {\n            'ema_slope_threshold': 450,\n            'ema_slope_15_threshold_max': 750,\n            'ema_slope_15_threshold_min': -750,\n            'ema_slope_60_threshold': 0.50,\n            'bearish_threshold_min': 0.5,\n            'bearish_threshold_max': 0.65,\n            'volume_threshold': 500,\n            'take_profit_multiplier': 1.0015,\n            'stop_loss_multiplier': 0.0005,\n            'quantity': '1000000',\n            'account_id': account_id\n        }\n    \n    def generate_signals(self, data):\n        config = self.config\n        \n        bearish_signals = data.apply(lambda x: 2 if (\n            x['bearish_2'] > config['bearish_threshold_min'] and\n            (x['EMA_slope_15'] > config['ema_slope_15_threshold_max'] or\n             x['EMA_slope_15'] < config['ema_slope_15_threshold_min']) and\n            x['volume'] > config['volume_threshold']\n        ) else 0, axis=1)\n\n        bullish_signals = data.apply(lambda x: 1 if (\n            x['bullish_1'] > config['bearish_threshold_min'] and\n            (x['EMA_slope_15'] > config['ema_slope_15_threshold_max'] or\n             x['EMA_slope_15'] < config['ema_slope_15_threshold_min']) and\n            x['volume'] > config['volume_threshold']\n        ) else 0, axis=1)\n\n        signals = pd.DataFrame({\n            'datetime': data['datetime'],\n            'bearish_flag': bearish_signals,\n            'bullish_flag': bullish_signals\n        })\n        \n        return signals\n    \n    def get_order_parameters(self, current_price, signal):\n        config = self.config\n        \n        if signal == 2:  # Bearish\n            return {\n                'take_profit': current_price * (1 + config['take_profit_multiplier']),\n                'stop_loss': config['stop_loss_multiplier'],\n                'quantity': config['quantity'],\n                'type': 'BUY',\n                'account_id': config['account_id']\n            }\n        elif signal == 1:  # Bullish\n            return {\n                'take_profit': current_price * (1 - config['take_profit_multiplier']),\n                'stop_loss': config['stop_loss_multiplier'],\n                'quantity': f\"-{config['quantity']}\",\n                'type': 'SELL',\n                'account_id': config['account_id']\n            }\n        return None\n\nclass EMASlopeStrategy(BaseStrategy):\n    def __init__(self):\n        super().__init__('ema_slope')\n    \n    def get_default_config(self):\n        return {\n            'ema_slope_threshold': -0.0002,\n            'ema_slope_15_threshold': -0.0001,\n            'ema_slope_60_threshold': 0,\n            'volume_mean_5_min': 450,\n            'volume_mean_5_max': 700,\n            'bearish_threshold_min': 0.5,\n            'bearish_threshold_max': 0.65,\n            'move_from_top_min': 0.08,\n            'move_from_top_max': 0.25,\n            'move_from_bottom_min': 0.08,\n            'move_from_bottom_max': 0.25,\n            'volume_min': 450,\n            'volume_max': 700,\n            'volume_mean_3_min': 500,\n            'volume_mean_3_max': 750,\n            'take_profit_multiplier': 1.002,\n            'stop_loss_multiplier': 0.001,\n            'quantity': '500000',\n            'account_id': account_id\n        }\n    \n    def generate_signals(self, data):\n        config = self.config\n        \n        bearish_signals = data.apply(lambda x: 2 if (\n            x['volume_mean_5'] >= config['volume_mean_5_min'] and\n            x['volume_mean_5'] <= config['volume_mean_5_max'] and\n            x['bearish_2'] >= config['bearish_threshold_min'] and\n            x['bearish_2'] <= config['bearish_threshold_max'] and\n            x['move_from_top'] >= config['move_from_top_min'] and\n            x['move_from_top'] <= config['move_from_top_max'] and\n            x['volume'] >= config['volume_min'] and\n            x['volume'] <= config['volume_max'] and\n            x['volume_mean_3'] >= config['volume_mean_3_min'] and\n            x['volume_mean_3'] <= config['volume_mean_3_max']\n        ) else 0, axis=1)\n\n        bullish_signals = data.apply(lambda x: 1 if (\n            x['volume'] >= config['volume_min'] and\n            x['volume'] <= config['volume_max'] and\n            x['volume_mean_3'] >= config['volume_mean_3_min'] and\n            x['volume_mean_3'] <= config['volume_mean_3_max'] and\n            x['volume_mean_5'] >= config['volume_mean_5_min'] and\n            x['volume_mean_5'] <= config['volume_mean_5_max'] and\n            x['bullish_1'] >= config['bearish_threshold_min'] and\n            x['bullish_1'] <= config['bearish_threshold_max'] and\n            x['move_from_bottom'] >= config['move_from_bottom_min'] and\n            x['move_from_bottom'] <= config['move_from_bottom_max']\n        ) else 0, axis=1)\n\n        signals = pd.DataFrame({\n            'datetime': data['datetime'],\n            'bearish_flag': bearish_signals,\n            'bullish_flag': bullish_signals\n        })\n        \n        return signals\n    \n    def get_order_parameters(self, current_price, signal):\n        config = self.config\n        \n        if signal == 1:  # Bullish\n            return {\n                'take_profit': current_price * (1 + config['take_profit_multiplier']),\n                'stop_loss': config['stop_loss_multiplier'],\n                'quantity': config['quantity'],\n                'type': 'BUY',\n                'account_id': config['account_id']\n            }\n        elif signal == 2:  # Bearish\n            return {\n                'take_profit': current_price * (1 - config['take_profit_multiplier']),\n                'stop_loss': config['stop_loss_multiplier'],\n                'quantity': f\"-{config['quantity']}\",\n                'type': 'SELL',\n                'account_id': config['account_id']\n            }\n        return None",
      "block_group": "86288f70820f4128b1cfc4b18c880480",
      "execution_count": 8,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "21794e8c",
        "execution_start": 1744216148922,
        "execution_millis": 328,
        "execution_context_id": "eef486c5-14b7-4560-ae68-60b6c0622fdc",
        "cell_id": "52b1e082631d41fca8a8dd78f26dad73",
        "deepnote_cell_type": "code"
      },
      "source": "# Initialize the system\ntrading_system = TradingSystem(access_token, bearish_model, bullish_model)\n\n# Register strategies\n#volume_strategy = VolumeBasedStrategy()\nvolume_strategy_hedge = VolumeBasedStrategyHedge()\nema_strategy = EMASlopeStrategy()\n\n#StrategyRegistry.register(volume_strategy)\nStrategyRegistry.register(volume_strategy_hedge)\nStrategyRegistry.register(ema_strategy)",
      "block_group": "ad04ba6aad8847a2bbc3cc519f349dab",
      "execution_count": 12,
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-04-09 16:29:09,246 - INFO - Strategy registered: volume_based_hedge\n2025-04-09 16:29:09,247 - INFO - Strategy registered: ema_slope\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "1c5085c4",
        "is_code_hidden": true,
        "execution_start": 1744216146322,
        "execution_millis": 5,
        "execution_context_id": "eef486c5-14b7-4560-ae68-60b6c0622fdc",
        "deepnote_app_is_code_hidden": true,
        "cell_id": "6437b2eff5874155af722cb26f1d337c",
        "deepnote_cell_type": "code"
      },
      "source": "import os\n\n# Check if logs directory exists and create if not\nlog_dir = 'logs'\nif not os.path.exists(log_dir):\n    os.makedirs(log_dir)\n\n# Test if log file is being written\nimport logging\n\n# Configure logging with both file and console handlers\nlogger = logging.getLogger('TradingSystem')\nlogger.setLevel(logging.INFO)\n\n# Clear any existing handlers\nlogger.handlers = []\n\n# Create file handler\nfile_handler = logging.FileHandler('logs/trading_system.log')\nfile_handler.setLevel(logging.INFO)\nfile_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nfile_handler.setFormatter(file_formatter)\n\n# Create console handler\nconsole_handler = logging.StreamHandler()\nconsole_handler.setLevel(logging.INFO)\nconsole_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nconsole_handler.setFormatter(console_formatter)\n\n# Add both handlers to logger\nlogger.addHandler(file_handler)\nlogger.addHandler(console_handler)\n\n# Test logging\nlogger.info(\"Test log message - checking if logging is working\")\n\n# Read and display the last few lines of the log file\ntry:\n    with open('logs/trading_system.log', 'r') as f:\n        last_lines = f.readlines()[-5:]  # Get last 5 lines\n        print(\"\\nLast few lines from log file:\")\n        for line in last_lines:\n            print(line.strip())\nexcept FileNotFoundError:\n    print(\"Log file not found!\")\nexcept Exception as e:\n    print(f\"Error reading log file: {str(e)}\")",
      "block_group": "7721ec0d405c4fb48da03c0d4d969f38",
      "execution_count": 10,
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-04-09 16:29:06,322 - INFO - Test log message - checking if logging is working\n\nLast few lines from log file:\n2025-04-09 16:26:03,740 - TradingSystem - INFO - volume_based_hedge SELL Order placed with order no: 533\n2025-04-09 16:26:04,114 - TradingSystem - INFO - Signals saved for strategy ema_slope\n2025-04-09 16:26:04,114 - TradingSystem - INFO - Execution completed at 2025-04-09 16:26:04.114614\n2025-04-09 16:29:06,322 - TradingSystem - INFO - Test log message - checking if logging is working\n2025-04-09 16:29:06,322 - TradingSystem - INFO - Test log message - checking if logging is working\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "6d0ee7c5",
        "execution_start": 1744216153176,
        "execution_millis": 2,
        "execution_context_id": "eef486c5-14b7-4560-ae68-60b6c0622fdc",
        "cell_id": "8d39940b102940aeb0c3f0af5595cba2",
        "deepnote_cell_type": "code"
      },
      "source": "def job():\n    trading_system.execute(lookback=100)",
      "block_group": "e7eb13f062ac44c891b1a1eef3ec8e2b",
      "execution_count": 14,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "5e68ed58",
        "execution_start": 1744216183426,
        "execution_millis": 0,
        "execution_context_id": "eef486c5-14b7-4560-ae68-60b6c0622fdc",
        "cell_id": "e38c3775cbce4c98bd5308a3decf99f0",
        "deepnote_cell_type": "code"
      },
      "source": "# Set up the schedule to run at specified intervals\nfor minute in [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55]:\n    # Schedule to run 30 seconds before each 5-minute mark\n    schedule.every().hour.at(f\"{minute:02d}:30\").do(job)  # Removed the leading colon",
      "block_group": "f26de8f42aeb4038a9c514548e1604a1",
      "execution_count": 18,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "9db07433",
        "execution_start": 1744216186298,
        "execution_millis": 15584576,
        "is_output_hidden": false,
        "execution_context_id": "eef486c5-14b7-4560-ae68-60b6c0622fdc",
        "deepnote_app_is_output_hidden": true,
        "cell_id": "e2b75dd7944840a6aec43f6b1881fad2",
        "deepnote_cell_type": "code"
      },
      "source": "print(\"Starting the trading bot...\")\nwhile True:\n    schedule.run_pending()\n    time.sleep(1)",
      "block_group": "3472ca3e039440d184c51551be756c4a",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Starting the trading bot...\n2025-04-09 16:30:30,953 - INFO - Raw data saved to data/raw/base_data.csv\n2025-04-09 16:30:31,507 - INFO - Processed data saved to data/processed/transformed_data.csv\n2025-04-09 16:30:32,364 - INFO - Raw data saved to data/predictions/predictions_data.csv\n2025-04-09 16:30:32,731 - INFO - Signals saved for strategy volume_based_hedge\n2025-04-09 16:30:33,127 - INFO - Signals saved for strategy ema_slope\n2025-04-09 16:30:33,129 - INFO - Execution completed at 2025-04-09 16:30:33.129010\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "982b6a55e126446383a76068fa133c9e",
        "deepnote_cell_type": "code"
      },
      "source": "",
      "block_group": "456700b80861456d974d1905f255b505",
      "execution_count": null,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=a127aa9e-0a77-4af9-a6ce-85e7a9b74042' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "deepnote_notebook_id": "11990d6ad3584e009dbd2e0e8ac5dabf"
  }
}