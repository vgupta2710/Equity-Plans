{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "80c24761",
        "execution_start": 1743801431452,
        "execution_millis": 4217,
        "execution_context_id": "3680201c-df4a-4720-99e0-2b55872bcea0",
        "cell_id": "f1cb90513f754d1492526212b7b8e8df",
        "deepnote_cell_type": "code"
      },
      "source": "import oandapyV20\nimport oandapyV20.endpoints.instruments as instruments\nimport pandas as pd\nimport numpy as np\nimport oandapyV20.endpoints.orders as orders\nfrom Moduled_functions import tranformation\nfrom Moduled_functions import calculate_ema_slope\nfrom sklearn.preprocessing import StandardScaler\nfrom keras.models import load_model\nbearish_model = load_model('/work/Trained_Models/FX_Bearish_model_2025-02-19.keras')\nbullish_model = load_model('/work/Trained_Models/FX_Bullish_model_2025-02-21.keras')",
      "block_group": "870fc101bcab43d19989fe2462c88dc6",
      "execution_count": 1,
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-04-04 21:17:12.524036: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2025-04-04 21:17:12.527461: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-04-04 21:17:12.557418: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-04-04 21:17:12.557504: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-04 21:17:12.558404: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-04-04 21:17:12.563534: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-04-04 21:17:12.564331: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-04-04 21:17:13.514417: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "f6f03c7f",
        "execution_start": 1743801920111,
        "execution_millis": 1,
        "execution_context_id": "3680201c-df4a-4720-99e0-2b55872bcea0",
        "cell_id": "139d0f3ea1694648aa7ab65b4cca52b4",
        "deepnote_cell_type": "code"
      },
      "source": "access_token = '320c03e29b3723c3869a2eafa278c553-c96eccee26e4e5864dcf001e98f7db84'\naccount_id_demo = '101-004-31059296-001'",
      "block_group": "009249c4d339491e80bf706bdb1dc476",
      "execution_count": 28,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "412c199f",
        "execution_start": 1743801435778,
        "execution_millis": 0,
        "execution_context_id": "3680201c-df4a-4720-99e0-2b55872bcea0",
        "cell_id": "accfa725a0774f518ec48cbef2a5ac12",
        "deepnote_cell_type": "code"
      },
      "source": "def place_order1(current_price,stoploss,target,qty,token,account_id):\n    order_details = {\n    \"order\": {\n        #\"price\": current_price,\n        #\"stopLossOnFill\": {\n        \"trailingStopLossOnFill\" : {   \n            \"timeInForce\": \"GTC\",\n            \"distance\": stoploss\n        },\n        \"takeProfitOnFill\": {\n            \"timeInForce\": \"GTC\",\n            \"price\": target\n        },\n        \"timeInForce\": \"FOK\",\n        \"instrument\": \"EUR_USD\",\n        \"units\": qty,\n        \"type\": \"MARKET\",\n        \"positionFill\": \"DEFAULT\"\n    }\n    }\n\n    client = oandapyV20.API(access_token=token)\n    r = orders.OrderCreate(accountID=account_id, data=order_details)\n    res = client.request(r)\n    return res\n",
      "block_group": "356a4f528f674592b819b749935f2937",
      "execution_count": 3,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "ae95c3c0",
        "execution_start": 1743801435837,
        "execution_millis": 69,
        "execution_context_id": "3680201c-df4a-4720-99e0-2b55872bcea0",
        "cell_id": "33423ca2b1b94a26a3306c7dc0dd0fb5",
        "deepnote_cell_type": "code"
      },
      "source": "from Moduled_functions import get_data\nfrom Moduled_functions import place_order\nbase_data,current_price = get_data(100, access_token)\n\ntake_profit = current_price * 0.9985  # 0.15% above\nstop_loss = current_price * 0.0005\nqty = '-1'",
      "block_group": "bba016fc176846b9b6d2f502bf1ac63e",
      "execution_count": 4,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "d2cc89c8",
        "execution_start": 1743801922314,
        "execution_millis": 118,
        "execution_context_id": "3680201c-df4a-4720-99e0-2b55872bcea0",
        "cell_id": "e8b21e8ebdda4e0fb08b8ef880053a2f",
        "deepnote_cell_type": "code"
      },
      "source": "place_order1(str(current_price),str(round(stop_loss,5)),str(round(take_profit,5)),qty,access_token,account_id_demo)",
      "block_group": "07639d0e8faa47e485821860c4883d7f",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/plain": "{'orderCreateTransaction': {'id': '969',\n  'accountID': '101-004-31059296-001',\n  'userID': 31059296,\n  'batchID': '969',\n  'requestID': '61357230905113915',\n  'time': '2025-04-04T21:25:22.414997332Z',\n  'type': 'MARKET_ORDER',\n  'instrument': 'EUR_USD',\n  'units': '-1',\n  'timeInForce': 'FOK',\n  'positionFill': 'DEFAULT',\n  'takeProfitOnFill': {'price': '1.09468', 'timeInForce': 'GTC'},\n  'trailingStopLossOnFill': {'distance': '0.00055',\n   'timeInForce': 'GTC',\n   'triggerMode': 'TOP_OF_BOOK'},\n  'reason': 'CLIENT_ORDER'},\n 'orderCancelTransaction': {'id': '970',\n  'accountID': '101-004-31059296-001',\n  'userID': 31059296,\n  'batchID': '969',\n  'requestID': '61357230905113915',\n  'time': '2025-04-04T21:25:22.414997332Z',\n  'type': 'ORDER_CANCEL',\n  'orderID': '969',\n  'reason': 'MARKET_HALTED'},\n 'relatedTransactionIDs': ['969', '970'],\n 'lastTransactionID': '970'}"
          },
          "metadata": {}
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "8595e4f2",
        "execution_start": 1743358882862,
        "execution_millis": 91,
        "execution_context_id": "20a19ed3-af5a-4d8c-aae3-1621850d90d8",
        "cell_id": "b1b99ba7527943ebbfd4fb2c7df370f6",
        "deepnote_cell_type": "code"
      },
      "source": "    params = {\n    \"granularity\": \"M5\",\n    \"from\" : '2024-10-17'\n    }\n    client = oandapyV20.API(access_token=access_token)\n    r = instruments.InstrumentsCandles(instrument=\"EUR_USD\",params=params)\n    dd = client.request(r)\n    candles = pd.DataFrame.from_records([{\n        'datetime': candle['time'],\n        'Open': float(candle['mid']['o']),\n        'High': float(candle['mid']['h']),\n        'Low': float(candle['mid']['l']),\n        'Close': float(candle['mid']['c']),\n        'volume': candle['volume'],\n    } for candle in dd['candles']])\n\n    candles[['Open', 'High', 'Low', 'Close']] = candles[['Open', 'High', 'Low', 'Close']].apply(lambda x: x*10000)\n    candles['datetime'] = pd.to_datetime(candles['datetime'])",
      "block_group": "b1b99ba7527943ebbfd4fb2c7df370f6",
      "execution_count": 3,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "3eb4ba5e",
        "execution_start": 1743375373252,
        "execution_millis": 1186664,
        "is_output_hidden": true,
        "sql_integration_id": "",
        "deepnote_table_state": {
          "sortBy": [],
          "filters": [],
          "pageSize": 10,
          "pageIndex": 5410,
          "columnOrder": [
            "datetime",
            "Open",
            "High",
            "Low",
            "Close",
            "volume"
          ],
          "hiddenColumnIds": [],
          "columnDisplayNames": [],
          "conditionalFilters": [],
          "cellFormattingRules": [],
          "wrappedTextColumnIds": []
        },
        "execution_context_id": "20a19ed3-af5a-4d8c-aae3-1621850d90d8",
        "deepnote_table_loading": false,
        "deepnote_variable_name": "",
        "deepnote_app_is_output_hidden": true,
        "cell_id": "cff95d47ca774f7e8565e39bfdbf35b3",
        "deepnote_cell_type": "code"
      },
      "source": "def fetch_candles(from_date):\n    params = {\n        \"granularity\": \"M5\",\n        \"from\": from_date,\n        \"count\": 500\n    }\n    r = instruments.InstrumentsCandles(instrument=\"EUR_USD\", params=params)\n    dd = client.request(r)\n    df = pd.DataFrame.from_records([{\n        'datetime': candle['time'],\n        'Open': float(candle['mid']['o']),\n        'High': float(candle['mid']['h']),\n        'Low': float(candle['mid']['l']),\n        'Close': float(candle['mid']['c']),\n        'volume': candle['volume'],\n    } for candle in dd['candles']])\n    \n    df[['Open', 'High', 'Low', 'Close']] = df[['Open', 'High', 'Low', 'Close']].apply(lambda x: x*10000)\n    df['datetime'] = pd.to_datetime(df['datetime'])\n    return df\n\n# Initialize variables\nstart_date = '2020-01-01'\nconsolidated_df = pd.DataFrame()\ncurrent_from = start_date\nmax_requests = 15000\n\nfor _ in range(max_requests):\n    try:\n        print(f\"Fetching data from: {current_from}\")\n        new_data = fetch_candles(current_from)\n        \n        if new_data.empty:\n            break\n            \n        consolidated_df = pd.concat([consolidated_df, new_data], ignore_index=True)\n        \n        # Get the maximum datetime and format it for next iteration\n        max_datetime = new_data['datetime'].max()\n        current_from = max_datetime.strftime('%Y-%m-%d')\n        \n        time.sleep(1)\n        \n    except Exception as e:\n        print(f\"Error: {e}\")\n        break\n\n# Remove any duplicates and sort\nconsolidated_df = consolidated_df.drop_duplicates(subset='datetime').sort_values('datetime')\nprint(f\"\\nTotal rows in consolidated data: {len(consolidated_df)}\")\nconsolidated_df",
      "block_group": "8c8b1850e5b14d3a83693c575625c386",
      "execution_count": 365,
      "outputs": [
        {
          "name": "stdout",
          "text": "Fetching data from: 2020-06-11\nFetching data from: 2020-06-14\nFetching data from: 2020-06-16\nFetching data from: 2020-06-17\nFetching data from: 2020-06-18\nFetching data from: 2020-06-21\nFetching data from: 2020-06-23\nFetching data from: 2020-06-24\nFetching data from: 2020-06-25\nFetching data from: 2020-06-28\nFetching data from: 2020-06-30\nFetching data from: 2020-07-01\nFetching data from: 2020-07-02\nFetching data from: 2020-07-05\nFetching data from: 2020-07-07\nFetching data from: 2020-07-08\nFetching data from: 2020-07-09\nFetching data from: 2020-07-12\nFetching data from: 2020-07-14\nFetching data from: 2020-07-15\nFetching data from: 2020-07-16\nFetching data from: 2020-07-19\nFetching data from: 2020-07-21\nFetching data from: 2020-07-22\nFetching data from: 2020-07-23\nFetching data from: 2020-07-26\nFetching data from: 2020-07-28\nFetching data from: 2020-07-29\nFetching data from: 2020-07-30\nFetching data from: 2020-08-02\nFetching data from: 2020-08-04\nFetching data from: 2020-08-05\nFetching data from: 2020-08-06\nFetching data from: 2020-08-09\nFetching data from: 2020-08-11\nFetching data from: 2020-08-12\nFetching data from: 2020-08-13\nFetching data from: 2020-08-16\nFetching data from: 2020-08-18\nFetching data from: 2020-08-19\nFetching data from: 2020-08-20\nFetching data from: 2020-08-23\nFetching data from: 2020-08-25\nFetching data from: 2020-08-26\nFetching data from: 2020-08-27\nFetching data from: 2020-08-30\nFetching data from: 2020-09-01\nFetching data from: 2020-09-02\nFetching data from: 2020-09-03\nFetching data from: 2020-09-06\nFetching data from: 2020-09-08\nFetching data from: 2020-09-09\nFetching data from: 2020-09-10\nFetching data from: 2020-09-13\nFetching data from: 2020-09-15\nFetching data from: 2020-09-16\nFetching data from: 2020-09-17\nFetching data from: 2020-09-20\nFetching data from: 2020-09-22\nFetching data from: 2020-09-23\nFetching data from: 2020-09-24\nFetching data from: 2020-09-27\nFetching data from: 2020-09-29\nFetching data from: 2020-09-30\nFetching data from: 2020-10-01\nFetching data from: 2020-10-04\nFetching data from: 2020-10-06\nFetching data from: 2020-10-07\nFetching data from: 2020-10-08\nFetching data from: 2020-10-11\nFetching data from: 2020-10-13\nFetching data from: 2020-10-14\nFetching data from: 2020-10-15\nFetching data from: 2020-10-18\nFetching data from: 2020-10-20\nFetching data from: 2020-10-21\nFetching data from: 2020-10-22\nFetching data from: 2020-10-25\nFetching data from: 2020-10-27\nFetching data from: 2020-10-28\nFetching data from: 2020-10-29\nFetching data from: 2020-11-01\nFetching data from: 2020-11-03\nFetching data from: 2020-11-04\nFetching data from: 2020-11-05\nFetching data from: 2020-11-08\nFetching data from: 2020-11-10\nFetching data from: 2020-11-11\nFetching data from: 2020-11-12\nFetching data from: 2020-11-15\nFetching data from: 2020-11-17\nFetching data from: 2020-11-18\nFetching data from: 2020-11-19\nFetching data from: 2020-11-22\nFetching data from: 2020-11-24\nFetching data from: 2020-11-25\nFetching data from: 2020-11-26\nFetching data from: 2020-11-29\nFetching data from: 2020-12-01\nFetching data from: 2020-12-02\nFetching data from: 2020-12-03\nFetching data from: 2020-12-06\nFetching data from: 2020-12-08\nFetching data from: 2020-12-09\nFetching data from: 2020-12-10\nFetching data from: 2020-12-13\nFetching data from: 2020-12-15\nFetching data from: 2020-12-16\nFetching data from: 2020-12-17\nFetching data from: 2020-12-20\nFetching data from: 2020-12-22\nFetching data from: 2020-12-23\nFetching data from: 2020-12-27\nFetching data from: 2020-12-29\nFetching data from: 2020-12-30\nFetching data from: 2021-01-03\nFetching data from: 2021-01-05\nFetching data from: 2021-01-06\nFetching data from: 2021-01-07\nFetching data from: 2021-01-10\nFetching data from: 2021-01-12\nFetching data from: 2021-01-13\nFetching data from: 2021-01-14\nFetching data from: 2021-01-17\nFetching data from: 2021-01-19\nFetching data from: 2021-01-20\nFetching data from: 2021-01-21\nFetching data from: 2021-01-24\nFetching data from: 2021-01-26\nFetching data from: 2021-01-27\nFetching data from: 2021-01-28\nFetching data from: 2021-01-31\nFetching data from: 2021-02-02\nFetching data from: 2021-02-03\nFetching data from: 2021-02-04\nFetching data from: 2021-02-07\nFetching data from: 2021-02-09\nFetching data from: 2021-02-10\nFetching data from: 2021-02-11\nFetching data from: 2021-02-14\nFetching data from: 2021-02-16\nFetching data from: 2021-02-17\nFetching data from: 2021-02-18\nFetching data from: 2021-02-21\nFetching data from: 2021-02-23\nFetching data from: 2021-02-24\nFetching data from: 2021-02-25\nFetching data from: 2021-02-28\nFetching data from: 2021-03-02\nFetching data from: 2021-03-03\nFetching data from: 2021-03-04\nFetching data from: 2021-03-07\nFetching data from: 2021-03-09\nFetching data from: 2021-03-10\nFetching data from: 2021-03-11\nFetching data from: 2021-03-14\nFetching data from: 2021-03-16\nFetching data from: 2021-03-17\nFetching data from: 2021-03-18\nFetching data from: 2021-03-21\nFetching data from: 2021-03-23\nFetching data from: 2021-03-24\nFetching data from: 2021-03-25\nFetching data from: 2021-03-28\nFetching data from: 2021-03-30\nFetching data from: 2021-03-31\nFetching data from: 2021-04-01\nFetching data from: 2021-04-04\nFetching data from: 2021-04-06\nFetching data from: 2021-04-07\nFetching data from: 2021-04-08\nFetching data from: 2021-04-11\nFetching data from: 2021-04-13\nFetching data from: 2021-04-14\nFetching data from: 2021-04-15\nFetching data from: 2021-04-18\nFetching data from: 2021-04-20\nFetching data from: 2021-04-21\nFetching data from: 2021-04-22\nFetching data from: 2021-04-25\nFetching data from: 2021-04-27\nFetching data from: 2021-04-28\nFetching data from: 2021-04-29\nFetching data from: 2021-05-02\nFetching data from: 2021-05-04\nFetching data from: 2021-05-05\nFetching data from: 2021-05-06\nFetching data from: 2021-05-09\nFetching data from: 2021-05-11\nFetching data from: 2021-05-12\nFetching data from: 2021-05-13\nFetching data from: 2021-05-16\nFetching data from: 2021-05-18\nFetching data from: 2021-05-19\nFetching data from: 2021-05-20\nFetching data from: 2021-05-23\nFetching data from: 2021-05-25\nFetching data from: 2021-05-26\nFetching data from: 2021-05-27\nFetching data from: 2021-05-30\nFetching data from: 2021-06-01\nFetching data from: 2021-06-02\nFetching data from: 2021-06-03\nFetching data from: 2021-06-06\nFetching data from: 2021-06-08\nFetching data from: 2021-06-09\nFetching data from: 2021-06-10\nFetching data from: 2021-06-13\nFetching data from: 2021-06-15\nFetching data from: 2021-06-16\nFetching data from: 2021-06-17\nFetching data from: 2021-06-20\nFetching data from: 2021-06-22\nFetching data from: 2021-06-23\nFetching data from: 2021-06-24\nFetching data from: 2021-06-27\nFetching data from: 2021-06-29\nFetching data from: 2021-06-30\nFetching data from: 2021-07-01\nFetching data from: 2021-07-04\nFetching data from: 2021-07-06\nFetching data from: 2021-07-07\nFetching data from: 2021-07-08\nFetching data from: 2021-07-11\nFetching data from: 2021-07-13\nFetching data from: 2021-07-14\nFetching data from: 2021-07-15\nFetching data from: 2021-07-18\nFetching data from: 2021-07-20\nFetching data from: 2021-07-21\nFetching data from: 2021-07-22\nFetching data from: 2021-07-25\nFetching data from: 2021-07-27\nFetching data from: 2021-07-28\nFetching data from: 2021-07-29\nFetching data from: 2021-08-01\nFetching data from: 2021-08-03\nFetching data from: 2021-08-04\nFetching data from: 2021-08-05\nFetching data from: 2021-08-08\nFetching data from: 2021-08-10\nFetching data from: 2021-08-11\nFetching data from: 2021-08-12\nFetching data from: 2021-08-15\nFetching data from: 2021-08-17\nFetching data from: 2021-08-18\nFetching data from: 2021-08-19\nFetching data from: 2021-08-22\nFetching data from: 2021-08-24\nFetching data from: 2021-08-25\nFetching data from: 2021-08-26\nFetching data from: 2021-08-29\nFetching data from: 2021-08-31\nFetching data from: 2021-09-01\nFetching data from: 2021-09-02\nFetching data from: 2021-09-05\nFetching data from: 2021-09-07\nFetching data from: 2021-09-08\nFetching data from: 2021-09-09\nFetching data from: 2021-09-12\nFetching data from: 2021-09-14\nFetching data from: 2021-09-15\nFetching data from: 2021-09-16\nFetching data from: 2021-09-19\nFetching data from: 2021-09-21\nFetching data from: 2021-09-22\nFetching data from: 2021-09-23\nFetching data from: 2021-09-26\nFetching data from: 2021-09-28\nFetching data from: 2021-09-29\nFetching data from: 2021-09-30\nFetching data from: 2021-10-03\nFetching data from: 2021-10-05\nFetching data from: 2021-10-06\nFetching data from: 2021-10-07\nFetching data from: 2021-10-10\nFetching data from: 2021-10-12\nFetching data from: 2021-10-13\nFetching data from: 2021-10-14\nFetching data from: 2021-10-17\nFetching data from: 2021-10-19\nFetching data from: 2021-10-20\nFetching data from: 2021-10-21\nFetching data from: 2021-10-24\nFetching data from: 2021-10-26\nFetching data from: 2021-10-27\nFetching data from: 2021-10-28\nFetching data from: 2021-10-31\nFetching data from: 2021-11-02\nFetching data from: 2021-11-03\nFetching data from: 2021-11-04\nFetching data from: 2021-11-07\nFetching data from: 2021-11-09\nFetching data from: 2021-11-10\nFetching data from: 2021-11-11\nFetching data from: 2021-11-14\nFetching data from: 2021-11-16\nFetching data from: 2021-11-17\nFetching data from: 2021-11-18\nFetching data from: 2021-11-22\nFetching data from: 2021-11-23\nFetching data from: 2021-11-24\nFetching data from: 2021-11-25\nFetching data from: 2021-11-28\nFetching data from: 2021-11-30\nFetching data from: 2021-12-01\nFetching data from: 2021-12-02\nFetching data from: 2021-12-05\nFetching data from: 2021-12-07\nFetching data from: 2021-12-08\nFetching data from: 2021-12-09\nFetching data from: 2021-12-12\nFetching data from: 2021-12-14\nFetching data from: 2021-12-15\nFetching data from: 2021-12-16\nFetching data from: 2021-12-19\nFetching data from: 2021-12-21\nFetching data from: 2021-12-22\nFetching data from: 2021-12-23\nFetching data from: 2021-12-26\nFetching data from: 2021-12-28\nFetching data from: 2021-12-29\nFetching data from: 2021-12-30\nFetching data from: 2022-01-02\nFetching data from: 2022-01-04\nFetching data from: 2022-01-05\nFetching data from: 2022-01-06\nFetching data from: 2022-01-09\nFetching data from: 2022-01-11\nFetching data from: 2022-01-12\nFetching data from: 2022-01-13\nFetching data from: 2022-01-16\nFetching data from: 2022-01-18\nFetching data from: 2022-01-19\nFetching data from: 2022-01-20\nFetching data from: 2022-01-23\nFetching data from: 2022-01-25\nFetching data from: 2022-01-26\nFetching data from: 2022-01-27\nFetching data from: 2022-01-30\nFetching data from: 2022-02-01\nFetching data from: 2022-02-02\nFetching data from: 2022-02-03\nFetching data from: 2022-02-06\nFetching data from: 2022-02-08\nFetching data from: 2022-02-09\nFetching data from: 2022-02-10\nFetching data from: 2022-02-13\nFetching data from: 2022-02-15\nFetching data from: 2022-02-16\nFetching data from: 2022-02-17\nFetching data from: 2022-02-20\nFetching data from: 2022-02-22\nFetching data from: 2022-02-23\nFetching data from: 2022-02-24\nFetching data from: 2022-02-27\nFetching data from: 2022-03-01\nFetching data from: 2022-03-02\nFetching data from: 2022-03-03\nFetching data from: 2022-03-06\nFetching data from: 2022-03-08\nFetching data from: 2022-03-09\nFetching data from: 2022-03-10\nFetching data from: 2022-03-13\nFetching data from: 2022-03-15\nFetching data from: 2022-03-16\nFetching data from: 2022-03-17\nFetching data from: 2022-03-20\nFetching data from: 2022-03-22\nFetching data from: 2022-03-23\nFetching data from: 2022-03-24\nFetching data from: 2022-03-27\nFetching data from: 2022-03-29\nFetching data from: 2022-03-30\nFetching data from: 2022-03-31\nFetching data from: 2022-04-03\nFetching data from: 2022-04-05\nFetching data from: 2022-04-06\nFetching data from: 2022-04-07\nFetching data from: 2022-04-10\nFetching data from: 2022-04-12\nFetching data from: 2022-04-13\nFetching data from: 2022-04-14\nFetching data from: 2022-04-17\nFetching data from: 2022-04-19\nFetching data from: 2022-04-20\nFetching data from: 2022-04-21\nFetching data from: 2022-04-24\nFetching data from: 2022-04-26\nFetching data from: 2022-04-27\nFetching data from: 2022-04-28\nFetching data from: 2022-05-01\nFetching data from: 2022-05-03\nFetching data from: 2022-05-04\nFetching data from: 2022-05-05\nFetching data from: 2022-05-08\nFetching data from: 2022-05-10\nFetching data from: 2022-05-11\nFetching data from: 2022-05-13\nFetching data from: 2022-05-16\nFetching data from: 2022-05-17\nFetching data from: 2022-05-18\nFetching data from: 2022-05-19\nFetching data from: 2022-05-22\nFetching data from: 2022-05-24\nFetching data from: 2022-05-25\nFetching data from: 2022-05-26\nFetching data from: 2022-05-29\nFetching data from: 2022-05-31\nFetching data from: 2022-06-01\nFetching data from: 2022-06-02\nFetching data from: 2022-06-05\nFetching data from: 2022-06-07\nFetching data from: 2022-06-08\nFetching data from: 2022-06-09\nFetching data from: 2022-06-12\nFetching data from: 2022-06-14\nFetching data from: 2022-06-15\nFetching data from: 2022-06-16\nFetching data from: 2022-06-19\nFetching data from: 2022-06-21\nFetching data from: 2022-06-22\nFetching data from: 2022-06-23\nFetching data from: 2022-06-26\nFetching data from: 2022-06-28\nFetching data from: 2022-06-29\nFetching data from: 2022-06-30\nFetching data from: 2022-07-03\nFetching data from: 2022-07-05\nFetching data from: 2022-07-06\nFetching data from: 2022-07-07\nFetching data from: 2022-07-10\nFetching data from: 2022-07-12\nFetching data from: 2022-07-13\nFetching data from: 2022-07-14\nFetching data from: 2022-07-17\nFetching data from: 2022-07-19\nFetching data from: 2022-07-20\nFetching data from: 2022-07-21\nFetching data from: 2022-07-24\nFetching data from: 2022-07-26\nFetching data from: 2022-07-27\nFetching data from: 2022-07-28\nFetching data from: 2022-07-31\nFetching data from: 2022-08-02\nFetching data from: 2022-08-03\nFetching data from: 2022-08-04\nFetching data from: 2022-08-07\nFetching data from: 2022-08-09\nFetching data from: 2022-08-10\nFetching data from: 2022-08-11\nFetching data from: 2022-08-14\nFetching data from: 2022-08-16\nFetching data from: 2022-08-17\nFetching data from: 2022-08-18\nFetching data from: 2022-08-21\nFetching data from: 2022-08-23\nFetching data from: 2022-08-24\nFetching data from: 2022-08-25\nFetching data from: 2022-08-28\nFetching data from: 2022-08-30\nFetching data from: 2022-08-31\nFetching data from: 2022-09-01\nFetching data from: 2022-09-04\nFetching data from: 2022-09-06\nFetching data from: 2022-09-07\nFetching data from: 2022-09-08\nFetching data from: 2022-09-11\nFetching data from: 2022-09-13\nFetching data from: 2022-09-14\nFetching data from: 2022-09-15\nFetching data from: 2022-09-18\nFetching data from: 2022-09-20\nFetching data from: 2022-09-21\nFetching data from: 2022-09-22\nFetching data from: 2022-09-25\nFetching data from: 2022-09-27\nFetching data from: 2022-09-28\nFetching data from: 2022-09-29\nFetching data from: 2022-10-02\nFetching data from: 2022-10-04\nFetching data from: 2022-10-05\nFetching data from: 2022-10-06\nFetching data from: 2022-10-09\nFetching data from: 2022-10-11\nFetching data from: 2022-10-12\nFetching data from: 2022-10-13\nFetching data from: 2022-10-16\nFetching data from: 2022-10-18\nFetching data from: 2022-10-19\nFetching data from: 2022-10-20\nFetching data from: 2022-10-23\nFetching data from: 2022-10-25\nFetching data from: 2022-10-26\nFetching data from: 2022-10-27\nFetching data from: 2022-10-30\nFetching data from: 2022-11-01\nFetching data from: 2022-11-02\nFetching data from: 2022-11-03\nFetching data from: 2022-11-06\nFetching data from: 2022-11-08\nFetching data from: 2022-11-09\nFetching data from: 2022-11-10\nFetching data from: 2022-11-13\nFetching data from: 2022-11-15\nFetching data from: 2022-11-16\nFetching data from: 2022-11-17\nFetching data from: 2022-11-20\nFetching data from: 2022-11-22\nFetching data from: 2022-11-23\nFetching data from: 2022-11-24\nFetching data from: 2022-11-27\nFetching data from: 2022-11-29\nFetching data from: 2022-11-30\nFetching data from: 2022-12-01\nFetching data from: 2022-12-04\nFetching data from: 2022-12-06\nFetching data from: 2022-12-07\nFetching data from: 2022-12-08\nFetching data from: 2022-12-11\nFetching data from: 2022-12-13\nFetching data from: 2022-12-14\nFetching data from: 2022-12-15\nFetching data from: 2022-12-18\nFetching data from: 2022-12-20\nFetching data from: 2022-12-21\nFetching data from: 2022-12-22\nFetching data from: 2022-12-26\nFetching data from: 2022-12-28\nFetching data from: 2022-12-29\nFetching data from: 2023-01-02\nFetching data from: 2023-01-03\nFetching data from: 2023-01-04\nFetching data from: 2023-01-05\nFetching data from: 2023-01-08\nFetching data from: 2023-01-10\nFetching data from: 2023-01-11\nFetching data from: 2023-01-12\nFetching data from: 2023-01-15\nFetching data from: 2023-01-17\nFetching data from: 2023-01-18\nFetching data from: 2023-01-19\nFetching data from: 2023-01-22\nFetching data from: 2023-01-24\nFetching data from: 2023-01-25\nFetching data from: 2023-01-26\nFetching data from: 2023-01-29\nFetching data from: 2023-01-31\nFetching data from: 2023-02-01\nFetching data from: 2023-02-02\nFetching data from: 2023-02-05\nFetching data from: 2023-02-07\nFetching data from: 2023-02-08\nFetching data from: 2023-02-09\nFetching data from: 2023-02-12\nFetching data from: 2023-02-14\nFetching data from: 2023-02-15\nFetching data from: 2023-02-16\nFetching data from: 2023-02-19\nFetching data from: 2023-02-21\nFetching data from: 2023-02-22\nFetching data from: 2023-02-23\nFetching data from: 2023-02-26\nFetching data from: 2023-02-28\nFetching data from: 2023-03-01\nFetching data from: 2023-03-02\nFetching data from: 2023-03-05\nFetching data from: 2023-03-07\nFetching data from: 2023-03-08\nFetching data from: 2023-03-09\nFetching data from: 2023-03-12\nFetching data from: 2023-03-14\nFetching data from: 2023-03-15\nFetching data from: 2023-03-16\nFetching data from: 2023-03-19\nFetching data from: 2023-03-21\nFetching data from: 2023-03-22\nFetching data from: 2023-03-23\nFetching data from: 2023-03-26\nFetching data from: 2023-03-28\nFetching data from: 2023-03-29\nFetching data from: 2023-03-30\nFetching data from: 2023-04-02\nFetching data from: 2023-04-04\nFetching data from: 2023-04-05\nFetching data from: 2023-04-06\nFetching data from: 2023-04-09\nFetching data from: 2023-04-11\nFetching data from: 2023-04-12\nFetching data from: 2023-04-13\nFetching data from: 2023-04-16\nFetching data from: 2023-04-18\nFetching data from: 2023-04-19\nFetching data from: 2023-04-20\nFetching data from: 2023-04-23\nFetching data from: 2023-04-25\nFetching data from: 2023-04-26\nFetching data from: 2023-04-27\nFetching data from: 2023-04-30\nFetching data from: 2023-05-02\nFetching data from: 2023-05-03\nFetching data from: 2023-05-04\nFetching data from: 2023-05-07\nFetching data from: 2023-05-09\nFetching data from: 2023-05-10\nFetching data from: 2023-05-11\nFetching data from: 2023-05-14\nFetching data from: 2023-05-16\nFetching data from: 2023-05-17\nFetching data from: 2023-05-18\nFetching data from: 2023-05-21\nFetching data from: 2023-05-23\nFetching data from: 2023-05-24\nFetching data from: 2023-05-25\nFetching data from: 2023-05-28\nFetching data from: 2023-05-30\nFetching data from: 2023-05-31\nFetching data from: 2023-06-01\nFetching data from: 2023-06-04\nFetching data from: 2023-06-06\nFetching data from: 2023-06-07\nFetching data from: 2023-06-08\nFetching data from: 2023-06-11\nFetching data from: 2023-06-13\nFetching data from: 2023-06-14\nFetching data from: 2023-06-15\nFetching data from: 2023-06-18\nFetching data from: 2023-06-20\nFetching data from: 2023-06-21\nFetching data from: 2023-06-22\nFetching data from: 2023-06-25\nFetching data from: 2023-06-27\nFetching data from: 2023-06-28\nFetching data from: 2023-06-29\nFetching data from: 2023-07-02\nFetching data from: 2023-07-04\nFetching data from: 2023-07-05\nFetching data from: 2023-07-06\nFetching data from: 2023-07-09\nFetching data from: 2023-07-11\nFetching data from: 2023-07-12\nFetching data from: 2023-07-13\nFetching data from: 2023-07-16\nFetching data from: 2023-07-18\nFetching data from: 2023-07-19\nFetching data from: 2023-07-20\nFetching data from: 2023-07-23\nFetching data from: 2023-07-25\nFetching data from: 2023-07-26\nFetching data from: 2023-07-27\nFetching data from: 2023-07-30\nFetching data from: 2023-08-01\nFetching data from: 2023-08-02\nFetching data from: 2023-08-03\nFetching data from: 2023-08-06\nFetching data from: 2023-08-08\nFetching data from: 2023-08-09\nFetching data from: 2023-08-10\nFetching data from: 2023-08-13\nFetching data from: 2023-08-15\nFetching data from: 2023-08-16\nFetching data from: 2023-08-17\nFetching data from: 2023-08-20\nFetching data from: 2023-08-22\nFetching data from: 2023-08-23\nFetching data from: 2023-08-24\nFetching data from: 2023-08-27\nFetching data from: 2023-08-29\nFetching data from: 2023-08-30\nFetching data from: 2023-08-31\nFetching data from: 2023-09-03\nFetching data from: 2023-09-05\nFetching data from: 2023-09-06\nFetching data from: 2023-09-07\nFetching data from: 2023-09-10\nFetching data from: 2023-09-12\nFetching data from: 2023-09-13\nFetching data from: 2023-09-14\nFetching data from: 2023-09-17\nFetching data from: 2023-09-19\nFetching data from: 2023-09-20\nFetching data from: 2023-09-21\nFetching data from: 2023-09-24\nFetching data from: 2023-09-26\nFetching data from: 2023-09-27\nFetching data from: 2023-09-28\nFetching data from: 2023-10-01\nFetching data from: 2023-10-03\nFetching data from: 2023-10-04\nFetching data from: 2023-10-05\nFetching data from: 2023-10-08\nFetching data from: 2023-10-10\nFetching data from: 2023-10-11\nFetching data from: 2023-10-12\nFetching data from: 2023-10-15\nFetching data from: 2023-10-17\nFetching data from: 2023-10-18\nFetching data from: 2023-10-19\nFetching data from: 2023-10-22\nFetching data from: 2023-10-24\nFetching data from: 2023-10-25\nFetching data from: 2023-10-26\nFetching data from: 2023-10-29\nFetching data from: 2023-10-31\nFetching data from: 2023-11-01\nFetching data from: 2023-11-02\nFetching data from: 2023-11-05\nFetching data from: 2023-11-07\nFetching data from: 2023-11-08\nFetching data from: 2023-11-09\nFetching data from: 2023-11-12\nFetching data from: 2023-11-14\nFetching data from: 2023-11-15\nFetching data from: 2023-11-16\nFetching data from: 2023-11-19\nFetching data from: 2023-11-21\nFetching data from: 2023-11-22\nFetching data from: 2023-11-23\nFetching data from: 2023-11-26\nFetching data from: 2023-11-28\nFetching data from: 2023-11-29\nFetching data from: 2023-11-30\nFetching data from: 2023-12-03\nFetching data from: 2023-12-05\nFetching data from: 2023-12-06\nFetching data from: 2023-12-07\nFetching data from: 2023-12-10\nFetching data from: 2023-12-12\nFetching data from: 2023-12-13\nFetching data from: 2023-12-14\nFetching data from: 2023-12-17\nFetching data from: 2023-12-19\nFetching data from: 2023-12-20\nFetching data from: 2023-12-21\nFetching data from: 2023-12-25\nFetching data from: 2023-12-27\nFetching data from: 2023-12-28\nFetching data from: 2024-01-01\nFetching data from: 2024-01-03\nFetching data from: 2024-01-04\nFetching data from: 2024-01-07\nFetching data from: 2024-01-09\nFetching data from: 2024-01-10\nFetching data from: 2024-01-11\nFetching data from: 2024-01-14\nFetching data from: 2024-01-16\nFetching data from: 2024-01-17\nFetching data from: 2024-01-18\nFetching data from: 2024-01-21\nFetching data from: 2024-01-23\nFetching data from: 2024-01-24\nFetching data from: 2024-01-25\nFetching data from: 2024-01-28\nFetching data from: 2024-01-30\nFetching data from: 2024-01-31\nFetching data from: 2024-02-01\nFetching data from: 2024-02-04\nFetching data from: 2024-02-06\nFetching data from: 2024-02-07\nFetching data from: 2024-02-08\nFetching data from: 2024-02-11\nFetching data from: 2024-02-13\nFetching data from: 2024-02-14\nFetching data from: 2024-02-15\nFetching data from: 2024-02-18\nFetching data from: 2024-02-20\nFetching data from: 2024-02-21\nFetching data from: 2024-02-22\nFetching data from: 2024-02-25\nFetching data from: 2024-02-27\nFetching data from: 2024-02-28\nFetching data from: 2024-02-29\nFetching data from: 2024-03-03\nFetching data from: 2024-03-05\nFetching data from: 2024-03-06\nFetching data from: 2024-03-07\nFetching data from: 2024-03-10\nFetching data from: 2024-03-12\nFetching data from: 2024-03-13\nFetching data from: 2024-03-14\nFetching data from: 2024-03-17\nFetching data from: 2024-03-19\nFetching data from: 2024-03-20\nFetching data from: 2024-03-21\nFetching data from: 2024-03-24\nFetching data from: 2024-03-26\nFetching data from: 2024-03-27\nFetching data from: 2024-03-28\nFetching data from: 2024-03-31\nFetching data from: 2024-04-02\nFetching data from: 2024-04-03\nFetching data from: 2024-04-04\nFetching data from: 2024-04-07\nFetching data from: 2024-04-09\nFetching data from: 2024-04-10\nFetching data from: 2024-04-11\nFetching data from: 2024-04-14\nFetching data from: 2024-04-16\nFetching data from: 2024-04-17\nFetching data from: 2024-04-18\nFetching data from: 2024-04-21\nFetching data from: 2024-04-23\nFetching data from: 2024-04-24\nFetching data from: 2024-04-25\nFetching data from: 2024-04-28\nFetching data from: 2024-04-30\nFetching data from: 2024-05-01\nFetching data from: 2024-05-02\nFetching data from: 2024-05-05\nFetching data from: 2024-05-07\nFetching data from: 2024-05-08\nFetching data from: 2024-05-09\nFetching data from: 2024-05-12\nFetching data from: 2024-05-14\nFetching data from: 2024-05-15\nFetching data from: 2024-05-16\nFetching data from: 2024-05-19\nFetching data from: 2024-05-21\nFetching data from: 2024-05-22\nFetching data from: 2024-05-23\nFetching data from: 2024-05-26\nFetching data from: 2024-05-28\nFetching data from: 2024-05-29\nFetching data from: 2024-05-30\nFetching data from: 2024-06-02\nFetching data from: 2024-06-04\nFetching data from: 2024-06-05\nFetching data from: 2024-06-06\nFetching data from: 2024-06-09\nFetching data from: 2024-06-11\nFetching data from: 2024-06-12\nFetching data from: 2024-06-13\nFetching data from: 2024-06-16\nFetching data from: 2024-06-18\nFetching data from: 2024-06-19\nFetching data from: 2024-06-20\nFetching data from: 2024-06-23\nFetching data from: 2024-06-25\nFetching data from: 2024-06-26\nFetching data from: 2024-06-27\nFetching data from: 2024-06-30\nFetching data from: 2024-07-02\nFetching data from: 2024-07-03\nFetching data from: 2024-07-04\nFetching data from: 2024-07-07\nFetching data from: 2024-07-09\nFetching data from: 2024-07-10\nFetching data from: 2024-07-11\nFetching data from: 2024-07-14\nFetching data from: 2024-07-16\nFetching data from: 2024-07-17\nFetching data from: 2024-07-18\nFetching data from: 2024-07-21\nFetching data from: 2024-07-23\nFetching data from: 2024-07-24\nFetching data from: 2024-07-25\nFetching data from: 2024-07-28\nFetching data from: 2024-07-30\nFetching data from: 2024-07-31\nFetching data from: 2024-08-01\nFetching data from: 2024-08-04\nFetching data from: 2024-08-06\nFetching data from: 2024-08-07\nFetching data from: 2024-08-08\nFetching data from: 2024-08-11\nFetching data from: 2024-08-13\nFetching data from: 2024-08-14\nFetching data from: 2024-08-15\nFetching data from: 2024-08-18\nFetching data from: 2024-08-20\nFetching data from: 2024-08-21\nFetching data from: 2024-08-22\nFetching data from: 2024-08-25\nFetching data from: 2024-08-27\nFetching data from: 2024-08-28\nFetching data from: 2024-08-29\nFetching data from: 2024-09-01\nFetching data from: 2024-09-03\nFetching data from: 2024-09-04\nFetching data from: 2024-09-05\nFetching data from: 2024-09-08\nFetching data from: 2024-09-10\nFetching data from: 2024-09-11\nFetching data from: 2024-09-12\nFetching data from: 2024-09-15\nFetching data from: 2024-09-17\nFetching data from: 2024-09-18\nFetching data from: 2024-09-19\nFetching data from: 2024-09-22\nFetching data from: 2024-09-24\nFetching data from: 2024-09-25\nFetching data from: 2024-09-26\nFetching data from: 2024-09-29\nFetching data from: 2024-10-01\nFetching data from: 2024-10-02\nFetching data from: 2024-10-03\nFetching data from: 2024-10-06\nFetching data from: 2024-10-08\nFetching data from: 2024-10-09\nFetching data from: 2024-10-10\nFetching data from: 2024-10-13\nFetching data from: 2024-10-15\nFetching data from: 2024-10-16\nFetching data from: 2024-10-17\nFetching data from: 2024-10-20\nFetching data from: 2024-10-22\nFetching data from: 2024-10-23\nFetching data from: 2024-10-24\nFetching data from: 2024-10-27\nFetching data from: 2024-10-29\nFetching data from: 2024-10-30\nFetching data from: 2024-10-31\nFetching data from: 2024-11-03\nFetching data from: 2024-11-05\nFetching data from: 2024-11-06\nFetching data from: 2024-11-07\nFetching data from: 2024-11-10\nFetching data from: 2024-11-12\nFetching data from: 2024-11-13\nFetching data from: 2024-11-14\nFetching data from: 2024-11-17\nFetching data from: 2024-11-19\nFetching data from: 2024-11-20\nFetching data from: 2024-11-21\nFetching data from: 2024-11-24\nFetching data from: 2024-11-26\nFetching data from: 2024-11-27\nFetching data from: 2024-11-28\nFetching data from: 2024-12-01\nFetching data from: 2024-12-03\nFetching data from: 2024-12-04\nFetching data from: 2024-12-05\nFetching data from: 2024-12-08\nFetching data from: 2024-12-10\nFetching data from: 2024-12-11\nFetching data from: 2024-12-12\nFetching data from: 2024-12-15\nFetching data from: 2024-12-17\nFetching data from: 2024-12-18\nFetching data from: 2024-12-19\nFetching data from: 2024-12-22\nFetching data from: 2024-12-24\nFetching data from: 2024-12-26\nFetching data from: 2024-12-29\nFetching data from: 2024-12-31\nFetching data from: 2025-01-02\nFetching data from: 2025-01-05\nFetching data from: 2025-01-07\nFetching data from: 2025-01-08\nFetching data from: 2025-01-09\nFetching data from: 2025-01-12\nFetching data from: 2025-01-14\nFetching data from: 2025-01-15\nFetching data from: 2025-01-16\nFetching data from: 2025-01-19\nFetching data from: 2025-01-21\nFetching data from: 2025-01-22\nFetching data from: 2025-01-23\nFetching data from: 2025-01-26\nFetching data from: 2025-01-28\nFetching data from: 2025-01-29\nFetching data from: 2025-01-30\nFetching data from: 2025-02-02\nFetching data from: 2025-02-04\nFetching data from: 2025-02-05\nFetching data from: 2025-02-06\nFetching data from: 2025-02-09\nFetching data from: 2025-02-11\nFetching data from: 2025-02-12\nFetching data from: 2025-02-13\nFetching data from: 2025-02-16\nFetching data from: 2025-02-18\nFetching data from: 2025-02-19\nFetching data from: 2025-02-20\nFetching data from: 2025-02-23\nFetching data from: 2025-02-25\nFetching data from: 2025-02-26\nFetching data from: 2025-02-27\nFetching data from: 2025-03-02\nFetching data from: 2025-03-04\nFetching data from: 2025-03-05\nFetching data from: 2025-03-06\nFetching data from: 2025-03-09\nFetching data from: 2025-03-11\nFetching data from: 2025-03-12\nFetching data from: 2025-03-13\nFetching data from: 2025-03-16\nFetching data from: 2025-03-18\nFetching data from: 2025-03-19\nFetching data from: 2025-03-20\nFetching data from: 2025-03-23\nFetching data from: 2025-03-25\nFetching data from: 2025-03-26\nFetching data from: 2025-03-27\nFetching data from: 2025-03-30\nFetching data from: 2025-03-30\nFetching data from: 2025-03-30\nFetching data from: 2025-03-30\nFetching data from: 2025-03-30\n",
          "output_type": "stream"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[365], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m     max_datetime \u001b[38;5;241m=\u001b[39m new_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\n\u001b[1;32m     45\u001b[0m     current_from \u001b[38;5;241m=\u001b[39m max_datetime\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "20f789c3",
        "execution_start": 1743376567499,
        "execution_millis": 4972,
        "execution_context_id": "20a19ed3-af5a-4d8c-aae3-1621850d90d8",
        "cell_id": "7ee022b8d66a4be380d280ce105fe016",
        "deepnote_cell_type": "code"
      },
      "source": "consolidated_df.to_csv('/work/Insights/Combined_data_volume_2020.csv')",
      "block_group": "50280353ec2d4ae79628172b37032b20",
      "execution_count": 367,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "afee3283",
        "execution_start": 1743642250472,
        "execution_millis": 3263,
        "deepnote_table_state": {
          "sortBy": [],
          "filters": [],
          "pageSize": 10,
          "pageIndex": 0,
          "columnOrder": [
            "datetime",
            "Open",
            "High",
            "Low",
            "Close",
            "volume"
          ],
          "hiddenColumnIds": [],
          "columnDisplayNames": [],
          "conditionalFilters": [],
          "cellFormattingRules": [],
          "wrappedTextColumnIds": []
        },
        "execution_context_id": "7cb1b84d-18b8-45a4-8eed-91ba91512a0a",
        "deepnote_table_loading": false,
        "cell_id": "e60bf5ab86354f929c5a7f41fbe6ca5c",
        "deepnote_cell_type": "code"
      },
      "source": "consolidated_df= pd.read_csv('/work/Insights/Combined_data_volume_2020.csv')\nconsolidated_df['datetime'] = pd.to_datetime(consolidated_df['datetime'])\nconsolidated_df.drop(columns=['Unnamed: 0'],inplace=True)",
      "block_group": "3b552e161c2b4a109201652c09e6f45b",
      "execution_count": 3,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "8ff3a26a",
        "execution_start": 1743642256254,
        "execution_millis": 42531,
        "execution_context_id": "7cb1b84d-18b8-45a4-8eed-91ba91512a0a",
        "cell_id": "f4261a40fd9d42b5b496f8c7c86e6879",
        "deepnote_cell_type": "code"
      },
      "source": "# Transform the data\nbase_data = tranformation(consolidated_df, 0.0015)\n\n# Calculate EMA slopes\nbase_data['EMA_slope'] = calculate_ema_slope(base_data, 'Open', 9)\nbase_data['EMA_slope_15'] = calculate_ema_slope(base_data, 'Open', 15)\nbase_data['EMA_slope_60'] = calculate_ema_slope(base_data, 'Open', 60)\n\n# Calculate deviation\nbase_data['deviation_'] = base_data['bullish_move_flag_20'] + base_data['bearish_move_flag_20']\nX = base_data.iloc[:,9:69]\ny = base_data['deviation_']\n\n# Normalize the data\nscaler = StandardScaler()\nscaler.fit(X)\nX_normalized = pd.DataFrame(scaler.transform(X)).round(1)\n\n# Get predictions\ny_pred_bearish = bearish_model.predict(X_normalized, verbose=0)\ny_pred_bearish = pd.DataFrame(y_pred_bearish)\n\ny_pred_bullish = bullish_model.predict(X_normalized, verbose=0)\ny_pred_bullish = pd.DataFrame(y_pred_bullish)\n\n# Combine results\nresult_combined = pd.concat([y_pred_bearish, y_pred_bullish, y], axis=1)\nresult_combined.columns = ['bearish_0','bearish_1','bearish_2','bearish_3',\n                            'bullish_0','bullish_1','bullish_2','bullish_3','y_true']\n\nbase_data = pd.concat([base_data, result_combined], axis=1)",
      "block_group": "63751abfd691472eb4294ac8403cc876",
      "execution_count": 5,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "e631d989",
        "execution_start": 1743359473468,
        "execution_millis": 71,
        "execution_context_id": "20a19ed3-af5a-4d8c-aae3-1621850d90d8",
        "cell_id": "46cfbed6f7b94a7a8b5331734632e8b2",
        "deepnote_cell_type": "code"
      },
      "source": "Can you isolate the bearish movement where y_true =2 and other values combined together. Evaluate feature importance from the below list, \nwith p-test validation confirm how good is the assumption here.\nAlso the ranges are required to confirm future assumptions for the top figured out feature.\n   ,'move_from_bottom'\n    ,'EMA_slope'\n    ,'volume'\n    ,'bearish_2'\n    ,'bullish_1'\n    ,'EMA_slope_60'\n    ,'move_from_top'\n    ,'volume_std_mean'\n    ,'volume_mean_5'\n    ,'volume_mean_3'",
      "block_group": "f10f51be65b3465289048f07c83e040a",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (2766469465.py, line 1)",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[22], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Can you isolate the bearish movement where y_true =2 and other values combined together. Evaluate feature importance from the below list, Also run some p-test validation confirm how good is the assumption here.\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "color": "purple",
        "cell_id": "5b2bd617943544c6b9e0edc4d853816b",
        "deepnote_cell_type": "text-cell-callout"
      },
      "source": "> Can you isolate the bearish movement where y_true =2 and other values combined together. Evaluate feature importance from the below list, \nwith p-test validation confirm how good is the assumption here.\nAlso the ranges are required to confirm future assumptions for the top figured out feature.\n   ,'move_from_bottom'\n    ,'EMA_slope'\n    ,'volume'\n    ,'bearish_2'\n    ,'bullish_1'\n    ,'EMA_slope_60'\n    ,'move_from_top'\n    ,'volume_std_mean'\n    ,'volume_mean_5'\n    ,'volume_mean_3'",
      "block_group": "60b17914886c4146b89d0c42eb440246"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "dee03885",
        "execution_start": 1743380066783,
        "execution_millis": 28,
        "execution_context_id": "c1797acf-5c4a-4f83-aef5-4cd311bdc7ee",
        "cell_id": "a70d5afe50dd477c8e981fe4e3d2ac3a",
        "deepnote_cell_type": "code"
      },
      "source": "base_data['date'] = base_data['datetime'].dt.date\nCY_base_data = base_data[base_data['date'] > pd.to_datetime('2025-01-01').date()]",
      "block_group": "593c594f745f412bb7f07fc64aa2b4dc",
      "execution_count": 24,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "c9829c817ce948d1ae8024a003fb92db",
        "deepnote_cell_type": "code"
      },
      "source": "#original bearish indictor values\nbase_data['bearish_flag']  = base_data.apply(lambda x:2 if x['volume_mean_5'] >590 ##433 \n                                                        and x['volume_mean_5'] <716\n                                                        and x['bearish_2'] > 0.510 \n                                                        and x['bearish_2'] < 0.626 \n                                                        and x['bullish_1'] > 0.509 \n                                                        and x['bullish_1'] < 0.609\n                                                        and x['move_from_top'] > 0.089 \n                                                        and x['move_from_top'] < 0.249\n                                                        and x['volume'] > 450 ##410 \n                                                        and x['volume'] <710\n                                                        and x['volume_mean_3'] > 418\n                                                        and x['volume_mean_3'] <732 else 0, axis=1)",
      "block_group": "b613e74dd6084980bc065afd32e84151",
      "execution_count": null,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "53dd779b91da421d80db5d7281b2aa1f",
        "deepnote_cell_type": "text-cell-h3"
      },
      "source": "### The optimal parameters are:\n- Volume: 450-700\n- Volume Mean 3: 500-750\n- Volume Mean 5: 450-750\n- Bearish_2: 0.50-0.65\n- Move from Top: 0.08-0.25",
      "block_group": "daacc8fa45ce4e1e81666624365b29fd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "66b39214",
        "execution_start": 1743380671112,
        "execution_millis": 215,
        "execution_context_id": "c1797acf-5c4a-4f83-aef5-4cd311bdc7ee",
        "cell_id": "f206de30856c42f8ad3598eec846c4f2",
        "deepnote_cell_type": "code"
      },
      "source": "CY_base_data['bearish_flag']  = CY_base_data.apply(lambda x:1 if x['volume_mean_5'] >450 ##433 \n                                                        and x['volume_mean_5'] <750\n                                                        and x['bearish_2'] > 0.50 \n                                                        and x['bearish_2'] < 0.65 \n                                                        #and x['bullish_1'] > 0.509 \n                                                        #and x['bullish_1'] < 0.609\n                                                        and x['move_from_top'] > 0.08\n                                                        and x['move_from_top'] < 0.25\n                                                        and x['volume'] > 450 ##410 \n                                                        and x['volume'] <700\n                                                        and x['volume_mean_3'] > 500\n                                                        and x['volume_mean_3'] <750 else 0, axis=1)",
      "block_group": "9901d642abbe408588ac9cb64e0c1a27",
      "execution_count": 50,
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_333/1479363735.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  CY_base_data['bearish_flag']  = CY_base_data.apply(lambda x:1 if x['volume_mean_5'] >450 ##433\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "f3a9cf2c",
        "execution_start": 1743380676701,
        "execution_millis": 2,
        "execution_context_id": "c1797acf-5c4a-4f83-aef5-4cd311bdc7ee",
        "cell_id": "e73781ead2374f85a7325854cc3d3874",
        "deepnote_cell_type": "code"
      },
      "source": "data = CY_base_data[CY_base_data['bearish_flag'] ==1]['y_true'].value_counts()\n((data[2])*50000) + ((data[0]+data[1]+data[3])*-17000)",
      "block_group": "432246e3644f4e9c949bab1e8a4b7d74",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 52,
          "data": {
            "text/plain": "1398000"
          },
          "metadata": {}
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "e6928a8f",
        "execution_start": 1743380089153,
        "execution_millis": 1,
        "execution_context_id": "c1797acf-5c4a-4f83-aef5-4cd311bdc7ee",
        "cell_id": "c6666c7d657d4503b8d8357176242fa1",
        "deepnote_cell_type": "code"
      },
      "source": "data",
      "block_group": "7df0135733cc4b30b5ac77ce3030b105",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 32,
          "data": {
            "text/plain": "y_true\n0    435\n2    251\n1    194\n3     27\nName: count, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "d4eb893f88914da19d335973c4ae861c",
        "deepnote_cell_type": "text-cell-h3"
      },
      "source": "### Parameters:\nvolume: (450, 700)\nvolume_mean_3: (600, 700)\nvolume_mean_5: (500, 700)\nbullish_1: (0.52, 0.6)\nmove_from_bottom: (0.12, 0.2)",
      "block_group": "24b6563ca96e4627996dce9fcc120795"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "5b494c2d",
        "execution_start": 1743380109382,
        "execution_millis": 205,
        "execution_context_id": "c1797acf-5c4a-4f83-aef5-4cd311bdc7ee",
        "cell_id": "04e875db9ade477ab51e5d3188654089",
        "deepnote_cell_type": "code"
      },
      "source": "## bullish indicator\nCY_base_data['bullish_flag'] = CY_base_data.apply(lambda x:1 if x['volume'] >= 450\n                                                        and x['volume'] <= 700\n                                                        and x['volume_mean_3'] >= 600\n                                                        and x['volume_mean_3'] <= 700\n                                                        and x['volume_mean_5'] >= 500\n                                                        and x['volume_mean_5'] <= 700\n                                                        and x['bullish_1'] >= 0.52\n                                                        and x['bullish_1'] <= 0.60\n                                                        and x['move_from_bottom'] >= 0.12\n                                                        and x['move_from_bottom'] <= 0.20 else 0, axis=1)",
      "block_group": "5aac8c76a1d441f4afbeeb79ff3d7085",
      "execution_count": 34,
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_333/3348931055.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  CY_base_data['bullish_flag'] = CY_base_data.apply(lambda x:1 if x['volume'] >= 450\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "a041711baa454458aa3ba4ad97e606f7",
        "deepnote_cell_type": "code"
      },
      "source": "#original bullish indictor values\nbase_data['bullish_flag'] = base_data.apply(lambda x:1 if x['volume'] >= 600##450\n                                                    and x['volume'] <= 700\n                                                    and x['volume_mean_3'] >= 550\n                                                    and x['volume_mean_3'] <= 700\n                                                    and x['volume_mean_5'] >= 590##550\n                                                    and x['volume_mean_5'] <= 700\n                                                    and x['bullish_1'] >= 0.51\n                                                    and x['bullish_1'] <= 0.60\n                                                    and x['move_from_bottom'] >= 0.10\n                                                    and x['move_from_bottom'] <= 0.20 else 0, axis=1)",
      "block_group": "96398d26ffc44b9ea543eeab66313e7a",
      "execution_count": null,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "b8f777fd",
        "execution_start": 1743380115290,
        "execution_millis": 2,
        "execution_context_id": "c1797acf-5c4a-4f83-aef5-4cd311bdc7ee",
        "cell_id": "1940c9f64fb1431692763c546fd37bee",
        "deepnote_cell_type": "code"
      },
      "source": "data = CY_base_data[CY_base_data['bullish_flag'] ==1]['y_true'].value_counts()\n((data[1])*50000) + ((data[0]+data[2]+data[3])*-17000)",
      "block_group": "8bfeae00441047ea93857f4e7cbe5822",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "129000"
          },
          "metadata": {}
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "e6928a8f",
        "execution_start": 1743380121321,
        "execution_millis": 0,
        "execution_context_id": "c1797acf-5c4a-4f83-aef5-4cd311bdc7ee",
        "cell_id": "3ca98040b27d416d962bcc39b1f8909a",
        "deepnote_cell_type": "code"
      },
      "source": "data",
      "block_group": "132098c2402c4ec9bdc9deaa652fa0d5",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 38,
          "data": {
            "text/plain": "y_true\n0    31\n2    28\n1    24\n3     4\nName: count, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "bad6047d",
        "execution_start": 1743380943012,
        "execution_millis": 0,
        "execution_context_id": "c1797acf-5c4a-4f83-aef5-4cd311bdc7ee",
        "cell_id": "07f4095b9602494a8ae0333767f84173",
        "deepnote_cell_type": "code"
      },
      "source": "(CY_base_data['date'].nunique()-12)",
      "block_group": "ed238ee6e7d54507a9bdbdaabab1ffc2",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 58,
          "data": {
            "text/plain": "63"
          },
          "metadata": {}
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "f39ae381",
        "execution_start": 1743380985080,
        "execution_millis": 4,
        "execution_context_id": "c1797acf-5c4a-4f83-aef5-4cd311bdc7ee",
        "cell_id": "e06843a4dcc94f32981ef482a02974e3",
        "deepnote_cell_type": "code"
      },
      "source": "(len(CY_base_data[CY_base_data['bearish_flag']==1]) + len(CY_base_data[CY_base_data['bullish_flag']==1])) / (CY_base_data['date'].nunique()-12)",
      "block_group": "d87820d11377423ea863abb4073ab519",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 64,
          "data": {
            "text/plain": "15.777777777777779"
          },
          "metadata": {}
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "2a57b26b",
        "execution_start": 1743378461609,
        "execution_millis": 25,
        "execution_context_id": "20a19ed3-af5a-4d8c-aae3-1621850d90d8",
        "cell_id": "26f798cb61aa4e00863682d1361fe0c5",
        "deepnote_cell_type": "code"
      },
      "source": "(len(base_data[base_data['bearish_flag']==2]) + len(base_data[base_data['bullish_flag']==1])) / base_data['date'].nunique()",
      "block_group": "7a1b32f8b324438a8cdbae58944a5945",
      "execution_count": 467,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 467,
          "data": {
            "text/plain": "9.33435207823961"
          },
          "metadata": {}
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "color": "purple",
        "cell_id": "ef21942b2a8e41758e70030dc66cf657",
        "deepnote_cell_type": "text-cell-callout"
      },
      "source": "> for the above bullish flag find a combination which has highest value profit booked from the features mentioned above.\nEvery correct bullish prediction, earns a USD 5000 profit and non-bullish move losses USD1700. Can you create a combination which has both higher profitability and good amount of trades also being made (not much tighter restrictions are preferred) ",
      "block_group": "8cf5f6db3821456c8bcb7be047c86d68"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "95785fb",
        "execution_start": 1743377830902,
        "execution_millis": 4409,
        "sql_integration_id": "",
        "execution_context_id": "20a19ed3-af5a-4d8c-aae3-1621850d90d8",
        "deepnote_variable_name": "",
        "cell_id": "48e64e467b9742b186e191b1516d1b98",
        "deepnote_cell_type": "code"
      },
      "source": "# Let's create a function to calculate profit\ndef calculate_profit(group):\n    profit = (group[group['y_true'] == 1].shape[0] * 50000) - \\\n             ((group[group['y_true'] != 1].shape[0]) * 17000)\n    trades = len(group)\n    return profit, trades\n\n# Create ranges to test for each feature\nfeature_ranges = {\n    'volume': [(450, 700), (500, 700), (550, 700), (600, 700)],\n    'volume_mean_3': [(450, 700), (500, 700), (550, 700), (600, 700)],\n    'volume_mean_5': [(450, 700), (500, 700), (550, 700), (600, 700)],\n    'bullish_1': [(0.50, 0.60), (0.51, 0.60), (0.52, 0.60)],\n    'move_from_bottom': [(0.08, 0.20), (0.10, 0.20), (0.12, 0.20)]\n}\n\nbest_profit = float('-inf')\nbest_combo = None\nbest_trades = 0\n\n# Test different combinations\nfor vol_range in feature_ranges['volume']:\n    for vol3_range in feature_ranges['volume_mean_3']:\n        for vol5_range in feature_ranges['volume_mean_5']:\n            for bull_range in feature_ranges['bullish_1']:\n                for move_range in feature_ranges['move_from_bottom']:\n                    \n                    # Apply conditions\n                    filtered_data = base_data[\n                        (base_data['volume'] >= vol_range[0]) &\n                        (base_data['volume'] <= vol_range[1]) &\n                        (base_data['volume_mean_3'] >= vol3_range[0]) &\n                        (base_data['volume_mean_3'] <= vol3_range[1]) &\n                        (base_data['volume_mean_5'] >= vol5_range[0]) &\n                        (base_data['volume_mean_5'] <= vol5_range[1]) &\n                        (base_data['bullish_1'] >= bull_range[0]) &\n                        (base_data['bullish_1'] <= bull_range[1]) &\n                        (base_data['move_from_bottom'] >= move_range[0]) &\n                        (base_data['move_from_bottom'] <= move_range[1])\n                    ]\n                    \n                    if len(filtered_data) > 0:\n                        profit, trades = calculate_profit(filtered_data)\n                        \n                        # Update best combination if profit is higher and trades are reasonable\n                        if profit > best_profit and trades >= 100:  # minimum 100 trades\n                            best_profit = profit\n                            best_combo = {\n                                'volume': vol_range,\n                                'volume_mean_3': vol3_range,\n                                'volume_mean_5': vol5_range,\n                                'bullish_1': bull_range,\n                                'move_from_bottom': move_range\n                            }\n                            best_trades = trades\n\nprint(\"Best Combination Found:\")\nprint(f\"Profit: ${best_profit:,}\")\nprint(f\"Number of Trades: {best_trades}\")\nprint(\"\\nParameters:\")\nfor feature, range_val in best_combo.items():\n    print(f\"{feature}: {range_val}\")\n\n# Let's analyze the distribution of y_true for this combination\nbest_filtered = base_data[\n    (base_data['volume'] >= best_combo['volume'][0]) &\n    (base_data['volume'] <= best_combo['volume'][1]) &\n    (base_data['volume_mean_3'] >= best_combo['volume_mean_3'][0]) &\n    (base_data['volume_mean_3'] <= best_combo['volume_mean_3'][1]) &\n    (base_data['volume_mean_5'] >= best_combo['volume_mean_5'][0]) &\n    (base_data['volume_mean_5'] <= best_combo['volume_mean_5'][1]) &\n    (base_data['bullish_1'] >= best_combo['bullish_1'][0]) &\n    (base_data['bullish_1'] <= best_combo['bullish_1'][1]) &\n    (base_data['move_from_bottom'] >= best_combo['move_from_bottom'][0]) &\n    (base_data['move_from_bottom'] <= best_combo['move_from_bottom'][1])\n]\n\nprint(\"\\nDistribution of outcomes:\")\nprint(best_filtered['y_true'].value_counts())",
      "block_group": "478d24c71c704ab8be516e35a173e927",
      "execution_count": 439,
      "outputs": [
        {
          "name": "stdout",
          "text": "Best Combination Found:\nProfit: $3,398,000\nNumber of Trades: 1416\n\nParameters:\nvolume: (450, 700)\nvolume_mean_3: (600, 700)\nvolume_mean_5: (500, 700)\nbullish_1: (0.52, 0.6)\nmove_from_bottom: (0.12, 0.2)\n\nDistribution of outcomes:\ny_true\n0    512\n2    452\n1    410\n3     42\nName: count, dtype: int64\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "ef86a2d1",
        "execution_start": 1743377843488,
        "execution_millis": 5356,
        "sql_integration_id": "",
        "execution_context_id": "20a19ed3-af5a-4d8c-aae3-1621850d90d8",
        "deepnote_variable_name": "",
        "cell_id": "3ce5581457c0418f8879f7623727ef31",
        "deepnote_cell_type": "code"
      },
      "source": "# Calculate average trades per day with this strategy\ntrades_per_day = best_trades / base_data['date'].nunique()\nsuccess_rate = (best_filtered[best_filtered['y_true'] == 1].shape[0] / best_trades) * 100\n\nprint(f\"Average trades per day: {trades_per_day:.2f}\")\nprint(f\"Success rate: {success_rate:.2f}%\")\nprint(f\"Average profit per trade: ${best_profit/best_trades:,.2f}\")\n\n# Update the bullish flag with the best combination\nbase_data['bullish_flag'] = base_data.apply(\n    lambda x: 1 if (x['volume'] >= best_combo['volume'][0]\n                   and x['volume'] <= best_combo['volume'][1]\n                   and x['volume_mean_3'] >= best_combo['volume_mean_3'][0]\n                   and x['volume_mean_3'] <= best_combo['volume_mean_3'][1]\n                   and x['volume_mean_5'] >= best_combo['volume_mean_5'][0]\n                   and x['volume_mean_5'] <= best_combo['volume_mean_5'][1]\n                   and x['bullish_1'] >= best_combo['bullish_1'][0]\n                   and x['bullish_1'] <= best_combo['bullish_1'][1]\n                   and x['move_from_bottom'] >= best_combo['move_from_bottom'][0]\n                   and x['move_from_bottom'] <= best_combo['move_from_bottom'][1])\n    else 0, axis=1)",
      "block_group": "535d52921b1043e29c9cef8edf0e40cc",
      "execution_count": 441,
      "outputs": [
        {
          "name": "stdout",
          "text": "Average trades per day: 0.87\nSuccess rate: 28.95%\nAverage profit per trade: $2,399.72\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bca2ece5c296408bb564ab28332a81f0",
        "deepnote_cell_type": "text-cell-p"
      },
      "source": "I found a more profitable combination that maintains a good number of trades while achieving better overall results. This combination:\n\n1. Makes $3,398,000 in total profit\n2. Generates about 1 trade per day (0.87)\n3. Has a success rate of ~29%\n4. Averages $2,399.72 profit per trade\n5. Total trades: 1,416 (good sample size)\n\nThe key differences from the previous settings:\n- Wider volume range (450-700)\n- Higher volume_mean_3 requirement (600-700)\n- More moderate volume_mean_5 range (500-700)\n- Stricter bullish_1 threshold (0.52-0.60)\n- Higher move_from_bottom minimum (0.12-0.20)\n\nThis combination provides a better balance between profitability and trading frequency while maintaining reasonable parameter ranges.",
      "block_group": "ef97c497d5934d21be202ae40f11d28f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "color": "purple",
        "cell_id": "3880d06859da4f55a20820b7c96c2d3e",
        "deepnote_cell_type": "text-cell-callout"
      },
      "source": "> Also build similar patters for bearish indicator.? the values for the profit  & loss remains same.",
      "block_group": "c36d8d6357a74ff8bba442b6f757aee9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bf70fd6af3364dd399379ab5ad12949b",
        "deepnote_cell_type": "text-cell-p"
      },
      "source": "I'll create a similar analysis for the bearish indicator, using the same profit ($50,000) and loss ($17,000) values, focusing on identifying optimal parameter combinations.",
      "block_group": "d305dd363e7d4cd8aeafced663c988e7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "86662da5",
        "execution_start": 1743378160922,
        "execution_millis": 13120,
        "sql_integration_id": "",
        "execution_context_id": "20a19ed3-af5a-4d8c-aae3-1621850d90d8",
        "deepnote_variable_name": "",
        "cell_id": "6caefce0e5e74d879a5b8a3bde92cc3c",
        "deepnote_cell_type": "code"
      },
      "source": "# Let's create a function to calculate profit for bearish trades\ndef calculate_bearish_profit(group):\n    profit = (group[group['y_true'] == 2].shape[0] * 50000) - \\\n             ((group[group['y_true'] != 2].shape[0]) * 17000)\n    trades = len(group)\n    return profit, trades\n\n# Create ranges to test for each feature\nfeature_ranges = {\n    'volume': [(450, 700), (500, 700), (550, 700), (600, 700)],\n    'volume_mean_3': [(400, 750), (450, 750), (500, 750), (550, 750)],\n    'volume_mean_5': [(450, 750), (500, 750), (550, 750), (600, 750)],\n    'bearish_2': [(0.50, 0.65), (0.51, 0.65), (0.52, 0.65)],\n    'move_from_top': [(0.08, 0.25), (0.09, 0.25), (0.10, 0.25)]\n}\n\nbest_profit = float('-inf')\nbest_combo = None\nbest_trades = 0\n\n# Test different combinations\nfor vol_range in feature_ranges['volume']:\n    for vol3_range in feature_ranges['volume_mean_3']:\n        for vol5_range in feature_ranges['volume_mean_5']:\n            for bear_range in feature_ranges['bearish_2']:\n                for move_range in feature_ranges['move_from_top']:\n                    \n                    # Apply conditions\n                    filtered_data = base_data[\n                        (base_data['volume'] >= vol_range[0]) &\n                        (base_data['volume'] <= vol_range[1]) &\n                        (base_data['volume_mean_3'] >= vol3_range[0]) &\n                        (base_data['volume_mean_3'] <= vol3_range[1]) &\n                        (base_data['volume_mean_5'] >= vol5_range[0]) &\n                        (base_data['volume_mean_5'] <= vol5_range[1]) &\n                        (base_data['bearish_2'] >= bear_range[0]) &\n                        (base_data['bearish_2'] <= bear_range[1]) &\n                        (base_data['move_from_top'] >= move_range[0]) &\n                        (base_data['move_from_top'] <= move_range[1])\n                    ]\n                    \n                    if len(filtered_data) > 0:\n                        profit, trades = calculate_bearish_profit(filtered_data)\n                        \n                        # Update best combination if profit is higher and trades are reasonable\n                        if profit > best_profit and trades >= 100:  # minimum 100 trades\n                            best_profit = profit\n                            best_combo = {\n                                'volume': vol_range,\n                                'volume_mean_3': vol3_range,\n                                'volume_mean_5': vol5_range,\n                                'bearish_2': bear_range,\n                                'move_from_top': move_range\n                            }\n                            best_trades = trades\n\nprint(\"Best Bearish Combination Found:\")\nprint(f\"Profit: ${best_profit:,}\")\nprint(f\"Number of Trades: {best_trades}\")\nprint(\"\\nParameters:\")\nfor feature, range_val in best_combo.items():\n    print(f\"{feature}: {range_val}\")\n\n# Let's analyze the distribution of y_true for this combination\nbest_filtered = base_data[\n    (base_data['volume'] >= best_combo['volume'][0]) &\n    (base_data['volume'] <= best_combo['volume'][1]) &\n    (base_data['volume_mean_3'] >= best_combo['volume_mean_3'][0]) &\n    (base_data['volume_mean_3'] <= best_combo['volume_mean_3'][1]) &\n    (base_data['volume_mean_5'] >= best_combo['volume_mean_5'][0]) &\n    (base_data['volume_mean_5'] <= best_combo['volume_mean_5'][1]) &\n    (base_data['bearish_2'] >= best_combo['bearish_2'][0]) &\n    (base_data['bearish_2'] <= best_combo['bearish_2'][1]) &\n    (base_data['move_from_top'] >= best_combo['move_from_top'][0]) &\n    (base_data['move_from_top'] <= best_combo['move_from_top'][1])\n]\n\nprint(\"\\nDistribution of outcomes:\")\nprint(best_filtered['y_true'].value_counts())\n\n# Calculate additional metrics\ntrades_per_day = best_trades / base_data['date'].nunique()\nsuccess_rate = (best_filtered[best_filtered['y_true'] == 2].shape[0] / best_trades) * 100\n\nprint(f\"\\nAverage trades per day: {trades_per_day:.2f}\")\nprint(f\"Success rate: {success_rate:.2f}%\")\nprint(f\"Average profit per trade: ${best_profit/best_trades:,.2f}\")\n\n# Update the bearish flag with the best combination\nbase_data['bearish_flag'] = base_data.apply(\n    lambda x: 2 if (x['volume'] >= best_combo['volume'][0]\n                   and x['volume'] <= best_combo['volume'][1]\n                   and x['volume_mean_3'] >= best_combo['volume_mean_3'][0]\n                   and x['volume_mean_3'] <= best_combo['volume_mean_3'][1]\n                   and x['volume_mean_5'] >= best_combo['volume_mean_5'][0]\n                   and x['volume_mean_5'] <= best_combo['volume_mean_5'][1]\n                   and x['bearish_2'] >= best_combo['bearish_2'][0]\n                   and x['bearish_2'] <= best_combo['bearish_2'][1]\n                   and x['move_from_top'] >= best_combo['move_from_top'][0]\n                   and x['move_from_top'] <= best_combo['move_from_top'][1])\n    else 0, axis=1)",
      "block_group": "dba4816709e34dc2ad10914a500ec53d",
      "execution_count": 451,
      "outputs": [
        {
          "name": "stdout",
          "text": "Best Bearish Combination Found:\nProfit: $41,470,000\nNumber of Trades: 13948\n\nParameters:\nvolume: (450, 700)\nvolume_mean_3: (500, 750)\nvolume_mean_5: (450, 750)\nbearish_2: (0.5, 0.65)\nmove_from_top: (0.08, 0.25)\n\nDistribution of outcomes:\ny_true\n0    6003\n2    4158\n1    3377\n3     410\nName: count, dtype: int64\n\nAverage trades per day: 8.53\nSuccess rate: 29.81%\nAverage profit per trade: $2,973.19\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "573cd478b7104464bc36d568e3cf96eb",
        "deepnote_cell_type": "text-cell-p"
      },
      "source": "I found a highly profitable combination for bearish trades that achieves excellent results. This combination:\n\n1. Makes $41,470,000 in total profit\n2. Generates about 9 trades per day (8.53)\n3. Has a success rate of ~30%\n4. Averages $2,973.19 profit per trade\n5. Total trades: 13,948 (very good sample size)\n\nThe optimal parameters are:\n- Volume: 450-700\n- Volume Mean 3: 500-750\n- Volume Mean 5: 450-750\n- Bearish_2: 0.50-0.65\n- Move from Top: 0.08-0.25\n\nThis combination provides significantly higher profitability than the bullish strategy, with more frequent trading opportunities while maintaining a similar success rate. The wider ranges for volume metrics and move_from_top allow for capturing more trading opportunities while still maintaining profitable selectivity.",
      "block_group": "712be0fbde1e40f0a878ec7aa00334ab"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "color": "purple",
        "cell_id": "9321b927ed6d498a86d9fe84cf705787",
        "deepnote_cell_type": "text-cell-callout"
      },
      "source": "> Create bullish flag find a combination which has highest value profit booked from the features mentioned below.\nEvery correct bullish prediction, earns a USD 5000 profit and non-bullish move losses USD1700. Can you create a combination which has both higher profitability and good amount of trades also being made (not much tighter restrictions are preferred).\nuse the features from the below:\n   ,'move_from_bottom'\n    ,'EMA_slope'\n    ,'volume'\n    ,'bearish_2'\n    ,'bullish_1'\n    ,'EMA_slope_60'\n    ,'move_from_top'\n    ,'volume_std_mean'\n    ,'volume_mean_5'\n    ,'volume_mean_3'\n    ,'EMA_slope_60'\n    ,'move_from_top'\n    ,'volume_std_mean'\n    ,'volume_mean_5'\n    ,'volume_mean_3'",
      "block_group": "36d74a116bdc42b6a07b1a47b093ba8a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "c0ad094167174493a8cc82b10898f8a4",
        "deepnote_cell_type": "text-cell-p"
      },
      "source": "I'll help analyze these features to find the optimal combination for bullish predictions. I'll create a comprehensive search through feature combinations, with a focus on profitability while maintaining a reasonable number of trades.",
      "block_group": "b7ae0d981e7b48ddb3b029f9d3aadcc9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "6bc9caca",
        "execution_start": 1743642613175,
        "execution_millis": 5051,
        "sql_integration_id": "",
        "execution_context_id": "7cb1b84d-18b8-45a4-8eed-91ba91512a0a",
        "deepnote_variable_name": "",
        "cell_id": "a277943898fd4398afb4940e2d000ea7",
        "deepnote_cell_type": "code"
      },
      "source": "# Let's create a function to calculate profit for bullish trades\ndef calculate_bullish_profit(group):\n    profit = (group[group['y_true'] == 1].shape[0] * 5000) - \\\n             ((group[group['y_true'] != 1].shape[0]) * 1700)\n    trades = len(group)\n    return profit, trades\n\n# Create ranges to test for each feature\nfeature_ranges = {\n    'volume': [(450, 700), (500, 700), (550, 700)],\n    'volume_mean_3': [(450, 700), (500, 700), (550, 700)],\n    'volume_mean_5': [(450, 700), (500, 700), (550, 700)],\n    'bullish_1': [(0.50, 0.60), (0.52, 0.60), (0.54, 0.60)],\n    'move_from_bottom': [(0.10, 0.20), (0.12, 0.20), (0.14, 0.20)],\n    'EMA_slope': [(0, float('inf')), (0.1, float('inf'))],\n    'EMA_slope_60': [(-float('inf'), 0), (-float('inf'), -0.1)],\n    'volume_std_mean': [(50, 150), (75, 150), (100, 150)]\n}\n\nbest_profit = float('-inf')\nbest_combo = None\nbest_trades = 0\n\n# Test combinations of core features first\nfor vol_range in feature_ranges['volume']:\n    for vol3_range in feature_ranges['volume_mean_3']:\n        for vol5_range in feature_ranges['volume_mean_5']:\n            for bull_range in feature_ranges['bullish_1']:\n                for move_range in feature_ranges['move_from_bottom']:\n                    for ema_range in feature_ranges['EMA_slope']:\n                        \n                        # Apply conditions\n                        filtered_data = base_data[\n                            (base_data['volume'] >= vol_range[0]) &\n                            (base_data['volume'] <= vol_range[1]) &\n                            (base_data['volume_mean_3'] >= vol3_range[0]) &\n                            (base_data['volume_mean_3'] <= vol3_range[1]) &\n                            (base_data['volume_mean_5'] >= vol5_range[0]) &\n                            (base_data['volume_mean_5'] <= vol5_range[1]) &\n                            (base_data['bullish_1'] >= bull_range[0]) &\n                            (base_data['bullish_1'] <= bull_range[1]) &\n                            (base_data['move_from_bottom'] >= move_range[0]) &\n                            (base_data['move_from_bottom'] <= move_range[1]) &\n                            (base_data['EMA_slope'] >= ema_range[0]) &\n                            (base_data['EMA_slope'] <= ema_range[1])\n                        ]\n                        \n                        if len(filtered_data) > 0:\n                            profit, trades = calculate_bullish_profit(filtered_data)\n                            \n                            # Update best combination if profit is higher and trades are reasonable\n                            if profit > best_profit and trades >= 100:  # minimum 100 trades\n                                best_profit = profit\n                                best_combo = {\n                                    'volume': vol_range,\n                                    'volume_mean_3': vol3_range,\n                                    'volume_mean_5': vol5_range,\n                                    'bullish_1': bull_range,\n                                    'move_from_bottom': move_range,\n                                    'EMA_slope': ema_range\n                                }\n                                best_trades = trades\n\nprint(\"Best Bullish Combination Found:\")\nprint(f\"Profit: ${best_profit:,}\")\nprint(f\"Number of Trades: {best_trades}\")\nprint(\"\\nParameters:\")\nfor feature, range_val in best_combo.items():\n    print(f\"{feature}: {range_val}\")\n\n# Analyze the distribution for the best combination\nbest_filtered = base_data[\n    (base_data['volume'] >= best_combo['volume'][0]) &\n    (base_data['volume'] <= best_combo['volume'][1]) &\n    (base_data['volume_mean_3'] >= best_combo['volume_mean_3'][0]) &\n    (base_data['volume_mean_3'] <= best_combo['volume_mean_3'][1]) &\n    (base_data['volume_mean_5'] >= best_combo['volume_mean_5'][0]) &\n    (base_data['volume_mean_5'] <= best_combo['volume_mean_5'][1]) &\n    (base_data['bullish_1'] >= best_combo['bullish_1'][0]) &\n    (base_data['bullish_1'] <= best_combo['bullish_1'][1]) &\n    (base_data['move_from_bottom'] >= best_combo['move_from_bottom'][0]) &\n    (base_data['move_from_bottom'] <= best_combo['move_from_bottom'][1]) &\n    (base_data['EMA_slope'] >= best_combo['EMA_slope'][0]) &\n    (base_data['EMA_slope'] <= best_combo['EMA_slope'][1])\n]\n\nprint(\"\\nDistribution of outcomes:\")\nprint(best_filtered['y_true'].value_counts())\n\n# Calculate additional metrics\ntrades_per_day = best_trades / base_data['date'].nunique()\nsuccess_rate = (best_filtered[best_filtered['y_true'] == 1].shape[0] / best_trades) * 100\n\nprint(f\"\\nAverage trades per day: {trades_per_day:.2f}\")\nprint(f\"Success rate: {success_rate:.2f}%\")\nprint(f\"Average profit per trade: ${best_profit/best_trades:,.2f}\")",
      "block_group": "9e6b40cf5dd0445eb114d2d2c6bbe635",
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "text": "Best Bullish Combination Found:\nProfit: $198,300\nNumber of Trades: 1247\n\nParameters:\nvolume: (550, 700)\nvolume_mean_3: (450, 700)\nvolume_mean_5: (450, 700)\nbullish_1: (0.54, 0.6)\nmove_from_bottom: (0.1, 0.2)\nEMA_slope: (0, inf)\n\nDistribution of outcomes:\ny_true\n0    479\n2    382\n1    346\n3     40\nName: count, dtype: int64\n",
          "output_type": "stream"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'date'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m~/venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 91\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts())\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Calculate additional metrics\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m trades_per_day \u001b[38;5;241m=\u001b[39m best_trades \u001b[38;5;241m/\u001b[39m \u001b[43mbase_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnunique()\n\u001b[1;32m     92\u001b[0m success_rate \u001b[38;5;241m=\u001b[39m (best_filtered[best_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m best_trades) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAverage trades per day: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrades_per_day\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/venv/lib/python3.10/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m~/venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'"
          ]
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "ffac6dd2",
        "execution_start": 1743642627211,
        "execution_millis": 5742,
        "sql_integration_id": "",
        "execution_context_id": "7cb1b84d-18b8-45a4-8eed-91ba91512a0a",
        "deepnote_variable_name": "",
        "cell_id": "456ccfc9225845f6b1a247dde5d2d172",
        "deepnote_cell_type": "code"
      },
      "source": "# Calculate additional metrics using datetime instead of date\ntrades_per_day = best_trades / base_data['datetime'].dt.date.nunique()\nsuccess_rate = (best_filtered[best_filtered['y_true'] == 1].shape[0] / best_trades) * 100\n\nprint(f\"Average trades per day: {trades_per_day:.2f}\")\nprint(f\"Success rate: {success_rate:.2f}%\")\nprint(f\"Average profit per trade: ${best_profit/best_trades:,.2f}\")\n\n# Update the bullish flag with the best combination\nbase_data['bullish_flag_new'] = base_data.apply(\n    lambda x: 1 if (x['volume'] >= best_combo['volume'][0]\n                   and x['volume'] <= best_combo['volume'][1]\n                   and x['volume_mean_3'] >= best_combo['volume_mean_3'][0]\n                   and x['volume_mean_3'] <= best_combo['volume_mean_3'][1]\n                   and x['volume_mean_5'] >= best_combo['volume_mean_5'][0]\n                   and x['volume_mean_5'] <= best_combo['volume_mean_5'][1]\n                   and x['bullish_1'] >= best_combo['bullish_1'][0]\n                   and x['bullish_1'] <= best_combo['bullish_1'][1]\n                   and x['move_from_bottom'] >= best_combo['move_from_bottom'][0]\n                   and x['move_from_bottom'] <= best_combo['move_from_bottom'][1]\n                   and x['EMA_slope'] >= best_combo['EMA_slope'][0]\n                   and x['EMA_slope'] <= best_combo['EMA_slope'][1])\n    else 0, axis=1)",
      "block_group": "8aff321ebf5643f1ba6b120fa9173a15",
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "text": "Average trades per day: 0.76\nSuccess rate: 27.75%\nAverage profit per trade: $159.02\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "c66bd13cfb3543fa948948151851e095",
        "deepnote_cell_type": "text-cell-p"
      },
      "source": "I found an optimized combination for bullish trades that provides consistent profitability while maintaining a reasonable number of trading opportunities. Here's a summary of the results:\n\n1. Total Profit: $198,300\n2. Number of Trades: 1,247\n3. Average trades per day: 0.76\n4. Success rate: 27.75%\n5. Average profit per trade: $159.02\n\nThe optimal parameters are:\n- Volume: 550-700\n- Volume Mean 3: 450-700\n- Volume Mean 5: 450-700\n- Bullish_1: 0.54-0.60\n- Move from Bottom: 0.10-0.20\n- EMA_slope: > 0 (positive slope)\n\nThis combination provides a balanced approach with:\n- Higher volume threshold (550) for primary volume but more flexible range for moving averages\n- Stricter bullish_1 signal requirement (0.54 minimum)\n- Reasonable move_from_bottom range\n- Positive EMA slope requirement for trend confirmation\n\nThe strategy generates about 1 trade per day with a reasonable success rate of nearly 28%. While the profit per trade is modest, the consistency and frequency of trades make it a viable strategy. The distribution of outcomes shows good selectivity in avoiding the worst outcomes (y_true = 3) while maintaining a balanced mix of other outcomes.",
      "block_group": "43c5b697603546e19807722ddca14512"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "color": "purple",
        "cell_id": "0b7718153fc549f38655fb299873a976",
        "deepnote_cell_type": "text-cell-callout"
      },
      "source": "> create a balanced combination for the bullish flag with maximum possible profitability? Other things can be ignored.",
      "block_group": "2e5fe978a9514a30a782fb81d966abfd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "9dd6c093765c4c87a48e83615ab60a0e",
        "deepnote_cell_type": "text-cell-p"
      },
      "source": "I'll create a comprehensive search focusing solely on maximizing profitability for the bullish flag, without constraints on number of trades or other metrics.",
      "block_group": "a2f135c4a3c9444b8f02ac5dd4de6904"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "563a75e0",
        "execution_start": 1743643585065,
        "execution_millis": 78250,
        "sql_integration_id": "",
        "execution_context_id": "7cb1b84d-18b8-45a4-8eed-91ba91512a0a",
        "deepnote_variable_name": "",
        "cell_id": "946db492855749cc82e6c0f06df10d3b",
        "deepnote_cell_type": "code"
      },
      "source": "# Let's create a function to calculate profit for bullish trades\ndef calculate_bullish_profit(group):\n    profit = (group[group['y_true'] == 1].shape[0] * 5000) - \\\n             ((group[group['y_true'] != 1].shape[0]) * 1700)\n    return profit\n\n# Create ranges to test for each feature\nfeature_ranges = {\n    'volume': [(400, 800), (450, 750), (500, 700), (550, 650)],\n    'volume_mean_3': [(400, 800), (450, 750), (500, 700), (550, 650)],\n    'volume_mean_5': [(400, 800), (450, 750), (500, 700), (550, 650)],\n    'bullish_1': [(0.50, 0.65), (0.52, 0.62), (0.54, 0.60), (0.56, 0.58)],\n    'move_from_bottom': [(0.05, 0.25), (0.08, 0.22), (0.10, 0.20), (0.12, 0.18)],\n    'EMA_slope': [(-0.1, float('inf')), (0, float('inf')), (0.1, float('inf'))],\n    'EMA_slope_60': [(-float('inf'), 0.1), (-float('inf'), 0), (-float('inf'), -0.1)]\n}\n\nbest_profit = float('-inf')\nbest_combo = None\nbest_filtered = None\n\n# Test different combinations\nfor vol_range in feature_ranges['volume']:\n    for vol3_range in feature_ranges['volume_mean_3']:\n        for vol5_range in feature_ranges['volume_mean_5']:\n            for bull_range in feature_ranges['bullish_1']:\n                for move_range in feature_ranges['move_from_bottom']:\n                    for ema_range in feature_ranges['EMA_slope']:\n                        for ema60_range in feature_ranges['EMA_slope_60']:\n                            \n                            # Apply conditions\n                            filtered_data = base_data[\n                                (base_data['volume'] >= vol_range[0]) &\n                                (base_data['volume'] <= vol_range[1]) &\n                                (base_data['volume_mean_3'] >= vol3_range[0]) &\n                                (base_data['volume_mean_3'] <= vol3_range[1]) &\n                                (base_data['volume_mean_5'] >= vol5_range[0]) &\n                                (base_data['volume_mean_5'] <= vol5_range[1]) &\n                                (base_data['bullish_1'] >= bull_range[0]) &\n                                (base_data['bullish_1'] <= bull_range[1]) &\n                                (base_data['move_from_bottom'] >= move_range[0]) &\n                                (base_data['move_from_bottom'] <= move_range[1]) &\n                                (base_data['EMA_slope'] >= ema_range[0]) &\n                                (base_data['EMA_slope'] <= ema_range[1]) &\n                                (base_data['EMA_slope_60'] >= ema60_range[0]) &\n                                (base_data['EMA_slope_60'] <= ema60_range[1])\n                            ]\n                            \n                            if len(filtered_data) > 0:\n                                profit = calculate_bullish_profit(filtered_data)\n                                \n                                if profit > best_profit:\n                                    best_profit = profit\n                                    best_combo = {\n                                        'volume': vol_range,\n                                        'volume_mean_3': vol3_range,\n                                        'volume_mean_5': vol5_range,\n                                        'bullish_1': bull_range,\n                                        'move_from_bottom': move_range,\n                                        'EMA_slope': ema_range,\n                                        'EMA_slope_60': ema60_range\n                                    }\n                                    best_filtered = filtered_data\n\nprint(\"Best Bullish Combination Found:\")\nprint(f\"Total Profit: ${best_profit:,}\")\nprint(\"\\nParameters:\")\nfor feature, range_val in best_combo.items():\n    print(f\"{feature}: {range_val}\")\n\nprint(\"\\nDistribution of outcomes:\")\nprint(best_filtered['y_true'].value_counts())\n\n# Calculate metrics\ntrades = len(best_filtered)\ntrades_per_day = trades / base_data['datetime'].dt.date.nunique()\nsuccess_rate = (best_filtered[best_filtered['y_true'] == 1].shape[0] / trades) * 100\nprofit_per_trade = best_profit/trades\n\nprint(f\"\\nNumber of trades: {trades}\")\nprint(f\"Average trades per day: {trades_per_day:.2f}\")\nprint(f\"Success rate: {success_rate:.2f}%\")\nprint(f\"Average profit per trade: ${profit_per_trade:.2f}\")",
      "block_group": "03ce5ec5699446778a1c4e4977b8c458",
      "execution_count": 37,
      "outputs": [
        {
          "name": "stdout",
          "text": "Best Bullish Combination Found:\nTotal Profit: $776,500\n\nParameters:\nvolume: (500, 700)\nvolume_mean_3: (400, 800)\nvolume_mean_5: (400, 800)\nbullish_1: (0.5, 0.65)\nmove_from_bottom: (0.08, 0.22)\nEMA_slope: (-0.1, inf)\nEMA_slope_60: (-inf, -0.1)\n\nDistribution of outcomes:\ny_true\n0    1140\n1     837\n2     804\n3      61\nName: count, dtype: int64\n\nNumber of trades: 2842\nAverage trades per day: 1.74\nSuccess rate: 29.45%\nAverage profit per trade: $273.22\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "cb39e360",
        "execution_start": 1743643671530,
        "execution_millis": 5648,
        "sql_integration_id": "",
        "execution_context_id": "7cb1b84d-18b8-45a4-8eed-91ba91512a0a",
        "deepnote_variable_name": "",
        "cell_id": "4804a66c928b47df91d829bc9a8425e9",
        "deepnote_cell_type": "code"
      },
      "source": "# Update the bullish flag with this most profitable combination\nbase_data['bullish_flag_new'] = base_data.apply(\n    lambda x: 1 if (x['volume'] >= best_combo['volume'][0]\n                   and x['volume'] <= best_combo['volume'][1]\n                   and x['volume_mean_3'] >= best_combo['volume_mean_3'][0]\n                   and x['volume_mean_3'] <= best_combo['volume_mean_3'][1]\n                   and x['volume_mean_5'] >= best_combo['volume_mean_5'][0]\n                   and x['volume_mean_5'] <= best_combo['volume_mean_5'][1]\n                   and x['bullish_1'] >= best_combo['bullish_1'][0]\n                   and x['bullish_1'] <= best_combo['bullish_1'][1]\n                   and x['move_from_bottom'] >= best_combo['move_from_bottom'][0]\n                   and x['move_from_bottom'] <= best_combo['move_from_bottom'][1]\n                   and x['EMA_slope'] >= best_combo['EMA_slope'][0]\n                   and x['EMA_slope'] <= best_combo['EMA_slope'][1]\n                   and x['EMA_slope_60'] >= best_combo['EMA_slope_60'][0]\n                   and x['EMA_slope_60'] <= best_combo['EMA_slope_60'][1])\n    else 0, axis=1)",
      "block_group": "2dcfbb9508d8496ab42c56673f6f13f3",
      "execution_count": 39,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "fc3152a8b58142c9890fc8057dbee9cf",
        "deepnote_cell_type": "text-cell-p"
      },
      "source": "I found a significantly more profitable combination for bullish trades by optimizing purely for profitability. The new combination achieves:\n\n1. Total Profit: $776,500 (nearly 4x improvement)\n2. Number of Trades: 2,842\n3. Average trades per day: 1.74\n4. Success rate: 29.45%\n5. Average profit per trade: $273.22\n\nKey features of this optimal combination:\n- More selective volume range (500-700) but wider ranges for moving averages (400-800)\n- Broader bullish_1 signal range (0.50-0.65)\n- Moderate move_from_bottom range (0.08-0.22)\n- Allows slightly negative EMA_slope (-0.1 to inf)\n- Requires negative long-term trend (EMA_slope_60 < -0.1)\n\nThis combination captures more trading opportunities while maintaining a good success rate and significantly higher profitability per trade. The negative long-term trend requirement combined with flexible short-term slope appears to identify better entry points for bullish moves.",
      "block_group": "0e573775388d4ec1ad105a6fc8831202"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "color": "purple",
        "cell_id": "11ab33362b4941eeba8bf821034a70c8",
        "deepnote_cell_type": "text-cell-callout"
      },
      "source": "> can you check how many bullish_1 > 0.7 were profitable. Give how many trades were made, avg trade per day and profitability. ",
      "block_group": "f5075cc19c3e492aa955433e16057000"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ee5a5cd7f6024fdd87925499ff838df6",
        "deepnote_cell_type": "text-cell-p"
      },
      "source": "I'll analyze the profitability of trades where bullish_1 is greater than 0.7.",
      "block_group": "e9c8f0475d4f423080d5a277487e47c2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "c1627d62",
        "execution_start": 1743644919975,
        "execution_millis": 72,
        "sql_integration_id": "",
        "execution_context_id": "7cb1b84d-18b8-45a4-8eed-91ba91512a0a",
        "deepnote_variable_name": "",
        "cell_id": "914b3658afc04a4d8fd5969c3a665165",
        "deepnote_cell_type": "code"
      },
      "source": "# Filter data where bullish_1 > 0.7\nhigh_bullish = base_data[base_data['bullish_1'] > 0.75]\n\n# Calculate metrics\ntotal_trades = len(high_bullish)\nprofitable_trades = len(high_bullish[high_bullish['y_true'] == 1])\ndays = base_data['datetime'].dt.date.nunique()\ntrades_per_day = total_trades / days\n\n# Calculate profitability (5000 for correct bullish, -1700 for incorrect)\nprofit = (profitable_trades * 5000) - ((total_trades - profitable_trades) * 1700)\n\nprint(f\"Total trades: {total_trades}\")\nprint(f\"Profitable trades: {profitable_trades}\")\nprint(f\"Average trades per day: {trades_per_day:.2f}\")\nprint(f\"Total profit: ${profit:,}\")\nprint(f\"Profit per trade: ${profit/total_trades:.2f}\")\nprint(f\"Success rate: {(profitable_trades/total_trades)*100:.2f}%\")\n\n# Show distribution of outcomes\nprint(\"\\nOutcome distribution:\")\nprint(high_bullish['y_true'].value_counts())",
      "block_group": "bbc9efee065f43dabd582ebf1f1ea618",
      "execution_count": 63,
      "outputs": [
        {
          "name": "stdout",
          "text": "Total trades: 24704\nProfitable trades: 7346\nAverage trades per day: 15.10\nTotal profit: $7,221,400\nProfit per trade: $292.32\nSuccess rate: 29.74%\n\nOutcome distribution:\ny_true\n0    7642\n2    7364\n1    7346\n3    2352\nName: count, dtype: int64\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "color": "purple",
        "cell_id": "17120118c46b46ed98f76330ea3837d5",
        "deepnote_cell_type": "text-cell-callout"
      },
      "source": "> can you find a combination for all the bullish_1> 0.7 compared to the bullish movement vs non-bullish movement. See if volume, ema slope values has help distinguish the movement somehow. ",
      "block_group": "5e6186851de94800b10a0692fd4172a2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "c515af82913e447787518b35f02deaf3",
        "deepnote_cell_type": "text-cell-p"
      },
      "source": "I'll analyze the high bullish signals (bullish_1 > 0.7) and look for patterns in volume and EMA slopes that distinguish between successful and unsuccessful bullish movements.",
      "block_group": "c50194168afe46cb96f3e66ea26eb3db"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "9d788a7e",
        "execution_start": 1743645038255,
        "execution_millis": 9,
        "sql_integration_id": "",
        "execution_context_id": "7cb1b84d-18b8-45a4-8eed-91ba91512a0a",
        "deepnote_variable_name": "",
        "cell_id": "115afe6acdac40eea4779f2c52ab3647",
        "deepnote_cell_type": "code"
      },
      "source": "# Analyze high bullish signals with various features\nhigh_bullish = base_data[base_data['bullish_1'] > 0.7].copy()\n\n# Create success flag (1 for bullish movement, 0 for others)\nhigh_bullish['success'] = (high_bullish['y_true'] == 1).astype(int)\n\n# Calculate mean values for key metrics grouped by success\nanalysis = high_bullish.groupby('success').agg({\n    'volume': ['mean', 'std'],\n    'volume_mean_3': ['mean', 'std'],\n    'volume_mean_5': ['mean', 'std'],\n    'EMA_slope': ['mean', 'std'],\n    'EMA_slope_15': ['mean', 'std'],\n    'EMA_slope_60': ['mean', 'std'],\n    'move_from_bottom': ['mean', 'std']\n}).round(3)\n\nprint(\"Feature Analysis for Bullish_1 > 0.7:\")\nprint(\"\\nMean and Standard Deviation by Success (1) vs Failure (0):\")\nprint(analysis)\n\n# Calculate success rate by volume ranges\nvolume_ranges = [(0, 300), (300, 500), (500, 700), (700, 1000), (1000, float('inf'))]\nvolume_analysis = []\n\nfor low, high in volume_ranges:\n    mask = (high_bullish['volume'] >= low) & (high_bullish['volume'] < high)\n    subset = high_bullish[mask]\n    if len(subset) > 0:\n        success_rate = (subset['success'].mean() * 100)\n        trades = len(subset)\n        volume_analysis.append({\n            'Volume Range': f\"{low}-{high}\",\n            'Success Rate %': round(success_rate, 2),\n            'Trades': trades\n        })\n\nprint(\"\\nSuccess Rate by Volume Range:\")\nfor result in volume_analysis:\n    print(f\"Volume {result['Volume Range']}: {result['Success Rate']}% ({result['Trades']} trades)\")",
      "block_group": "f0cc6be339fa4674ad081fe08bdeeb9c",
      "execution_count": 65,
      "outputs": [
        {
          "name": "stdout",
          "text": "Feature Analysis for Bullish_1 > 0.7:\n\nMean and Standard Deviation by Success (1) vs Failure (0):\n          volume          volume_mean_3          volume_mean_5           \\\n            mean      std          mean      std          mean      std   \nsuccess                                                                   \n0        784.644  646.332       803.974  639.433       815.678  622.617   \n1        893.383  624.690       914.111  631.588       918.342  604.766   \n\n        EMA_slope        EMA_slope_15        EMA_slope_60         \\\n             mean    std         mean    std         mean    std   \nsuccess                                                            \n0           0.014  2.644        0.011  2.045        0.010  0.986   \n1           0.025  2.659        0.029  2.101        0.008  1.070   \n\n        move_from_bottom         \n                    mean    std  \nsuccess                          \n0                  0.375  0.319  \n1                  0.406  0.330  \n\nSuccess Rate by Volume Range:\n",
          "output_type": "stream"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Success Rate'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[65], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSuccess Rate by Volume Range:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m volume_analysis:\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVolume \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVolume Range\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSuccess Rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrades\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m trades)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Success Rate'"
          ]
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "ff4a44e6",
        "execution_start": 1743645046825,
        "execution_millis": 1,
        "sql_integration_id": "",
        "execution_context_id": "7cb1b84d-18b8-45a4-8eed-91ba91512a0a",
        "deepnote_variable_name": "",
        "cell_id": "b28d5b708aa7496cb509a3c627bb80ff",
        "deepnote_cell_type": "code"
      },
      "source": "# Let's fix the volume analysis print statement\nprint(\"\\nSuccess Rate by Volume Range:\")\nfor result in volume_analysis:\n    print(f\"Volume {result['Volume Range']}: {result['Success Rate %']}% ({result['Trades']} trades)\")\n\n# Let's also analyze EMA slope ranges\nema_ranges = [\n    (-float('inf'), -0.5),\n    (-0.5, 0),\n    (0, 0.5),\n    (0.5, float('inf'))\n]\n\nema_analysis = []\nfor low, high in ema_ranges:\n    mask = (high_bullish['EMA_slope'] >= low) & (high_bullish['EMA_slope'] < high)\n    subset = high_bullish[mask]\n    if len(subset) > 0:\n        success_rate = (subset['success'].mean() * 100)\n        trades = len(subset)\n        ema_analysis.append({\n            'EMA Range': f\"{low:.1f} to {high:.1f}\",\n            'Success Rate': round(success_rate, 2),\n            'Trades': trades\n        })\n\nprint(\"\\nSuccess Rate by EMA Slope Range:\")\nfor result in ema_analysis:\n    print(f\"EMA Slope {result['EMA Range']}: {result['Success Rate']}% ({result['Trades']} trades)\")",
      "block_group": "506dedb1a1ba410f8732aff36d1d21e5",
      "execution_count": 67,
      "outputs": [
        {
          "name": "stdout",
          "text": "\nSuccess Rate by Volume Range:\nVolume 0-300: 17.68% (4226 trades)\nVolume 300-500: 27.48% (4629 trades)\nVolume 500-700: 30.93% (4410 trades)\nVolume 700-1000: 33.74% (4481 trades)\nVolume 1000-inf: 35.23% (6958 trades)\n\nSuccess Rate by EMA Slope Range:\nEMA Slope -inf to -0.5: 31.57% (9163 trades)\nEMA Slope -0.5 to 0.0: 25.79% (3315 trades)\nEMA Slope 0.0 to 0.5: 24.99% (3269 trades)\nEMA Slope 0.5 to inf: 31.05% (8957 trades)\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "5b840486",
        "execution_start": 1743645057236,
        "execution_millis": 13,
        "sql_integration_id": "",
        "execution_context_id": "7cb1b84d-18b8-45a4-8eed-91ba91512a0a",
        "deepnote_variable_name": "",
        "cell_id": "cb6f9eea9ae4407380f887a081e9d545",
        "deepnote_cell_type": "code"
      },
      "source": "# Let's analyze combinations of volume and EMA slope\n# We'll focus on the most promising ranges\n\n# Define the most promising ranges based on previous analysis\nvolume_ranges = [(500, 700), (700, 1000), (1000, float('inf'))]\nema_ranges = [(-float('inf'), -0.5), (0.5, float('inf'))]\n\nprint(\"Analysis of Volume + EMA Slope Combinations:\")\nprint(\"==========================================\")\n\nfor vol_low, vol_high in volume_ranges:\n    for ema_low, ema_high in ema_ranges:\n        mask = (\n            (high_bullish['volume'] >= vol_low) & \n            (high_bullish['volume'] < vol_high) &\n            (high_bullish['EMA_slope'] >= ema_low) & \n            (high_bullish['EMA_slope'] < ema_high)\n        )\n        subset = high_bullish[mask]\n        if len(subset) > 0:\n            success_rate = (subset['success'].mean() * 100)\n            trades = len(subset)\n            profit = (subset['success'].sum() * 5000) - ((len(subset) - subset['success'].sum()) * 1700)\n            profit_per_trade = profit / trades if trades > 0 else 0\n            \n            print(f\"\\nVolume {vol_low}-{vol_high}, EMA Slope {ema_low:.1f} to {ema_high:.1f}\")\n            print(f\"Success Rate: {success_rate:.2f}%\")\n            print(f\"Number of Trades: {trades}\")\n            print(f\"Total Profit: ${profit:,.2f}\")\n            print(f\"Profit per Trade: ${profit_per_trade:.2f}\")\n            print(f\"Trades per Day: {trades/days:.2f}\")",
      "block_group": "8d64075ad64c4e66b697b2b14bad481b",
      "execution_count": 69,
      "outputs": [
        {
          "name": "stdout",
          "text": "Analysis of Volume + EMA Slope Combinations:\n==========================================\n\nVolume 500-700, EMA Slope -inf to -0.5\nSuccess Rate: 30.47%\nNumber of Trades: 1582\nTotal Profit: $540,000.00\nProfit per Trade: $341.34\nTrades per Day: 0.97\n\nVolume 500-700, EMA Slope 0.5 to inf\nSuccess Rate: 32.32%\nNumber of Trades: 1612\nTotal Profit: $750,300.00\nProfit per Trade: $465.45\nTrades per Day: 0.99\n\nVolume 700-1000, EMA Slope -inf to -0.5\nSuccess Rate: 33.60%\nNumber of Trades: 1780\nTotal Profit: $980,600.00\nProfit per Trade: $550.90\nTrades per Day: 1.09\n\nVolume 700-1000, EMA Slope 0.5 to inf\nSuccess Rate: 35.37%\nNumber of Trades: 1685\nTotal Profit: $1,128,700.00\nProfit per Trade: $669.85\nTrades per Day: 1.03\n\nVolume 1000-inf, EMA Slope -inf to -0.5\nSuccess Rate: 35.61%\nNumber of Trades: 3100\nTotal Profit: $2,126,800.00\nProfit per Trade: $686.06\nTrades per Day: 1.89\n\nVolume 1000-inf, EMA Slope 0.5 to inf\nSuccess Rate: 34.96%\nNumber of Trades: 3021\nTotal Profit: $1,939,500.00\nProfit per Trade: $642.01\nTrades per Day: 1.85\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "8841430dcb654db59edfc5c32057bd44",
        "deepnote_cell_type": "text-cell-p"
      },
      "source": "Based on the analysis of trades with bullish_1 > 0.7, several key patterns emerge:\n\n1. Volume Impact:\n- Higher volume correlates with better success rates\n- Success rates increase steadily with volume:\n  * 17.68% for volume 0-300\n  * 35.23% for volume >1000\n\n2. EMA Slope Patterns:\n- Strong negative (<-0.5) and strong positive (>0.5) slopes perform best\n- Success rates:\n  * 31.57% for strong negative slope\n  * 31.05% for strong positive slope\n  * Lower success rates (24-25%) for moderate slopes\n\n3. Best Combinations:\nThe most profitable combination is:\n- Volume >1000 with strong negative EMA slope\n  * 35.61% success rate\n  * $686.06 profit per trade\n  * 1.89 trades per day\n  * Total profit: $2,126,800\n\nSecond best:\n- Volume 700-1000 with positive EMA slope\n  * 35.37% success rate\n  * $669.85 profit per trade\n  * 1.03 trades per day\n  * Total profit: $1,128,700\n\nThis suggests that high volume combined with strong trend movement (either direction) provides the best trading opportunities when bullish_1 > 0.7.",
      "block_group": "b96c455fa0cc42ef89c929f2834d010d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "9cee9d58",
        "execution_start": 1743801975868,
        "execution_millis": 509,
        "execution_context_id": "3680201c-df4a-4720-99e0-2b55872bcea0",
        "cell_id": "33b9888473be4b12bca61a8c522697d5",
        "deepnote_cell_type": "code"
      },
      "source": "history = pd.read_csv('/work/base_data_history.csv')\nhistory = history.iloc[-300:]",
      "block_group": "9c22693543c049e1a11fb266d6e73387",
      "execution_count": 32,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "fd46fbf7",
        "execution_start": 1743801981062,
        "execution_millis": 7,
        "deepnote_table_state": {
          "sortBy": [],
          "filters": [],
          "pageSize": 25,
          "pageIndex": 3,
          "columnOrder": [
            "datetime",
            "y_true",
            "EMA_slope_15",
            "EMA_slope",
            "bullish_1",
            "volume",
            "move_from_bottom"
          ],
          "hiddenColumnIds": [],
          "columnDisplayNames": [],
          "conditionalFilters": [],
          "cellFormattingRules": [],
          "wrappedTextColumnIds": []
        },
        "execution_context_id": "3680201c-df4a-4720-99e0-2b55872bcea0",
        "deepnote_table_loading": false,
        "cell_id": "6d76b78ff11b44818ed1c33ad3c132db",
        "deepnote_cell_type": "code"
      },
      "source": "history[(history['volume']> 600)\n        & (history['bullish_1']> 0.7)\n        & ((history['EMA_slope_15']>0.25) | (history['EMA_slope_15']<-0.25))\n       & (history['move_from_bottom']>0.05) #& (history['move_from_bottom']<0.95) \n][['datetime','y_true','EMA_slope_15','EMA_slope','bullish_1','volume','move_from_bottom']]\n#]['y_true'].value_counts()",
      "block_group": "c02341f63407406dbf10e09ef597d0f4",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "application/vnd.deepnote.dataframe.v3+json": {
              "column_count": 7,
              "row_count": 1,
              "columns": [
                {
                  "name": "datetime",
                  "dtype": "object",
                  "stats": {
                    "unique_count": 1,
                    "nan_count": 0,
                    "categories": [
                      {
                        "name": "2025-04-04 18:15:00+00:00",
                        "count": 1
                      }
                    ]
                  }
                },
                {
                  "name": "y_true",
                  "dtype": "int64",
                  "stats": {
                    "unique_count": 1,
                    "nan_count": 0,
                    "min": "2",
                    "max": "2",
                    "histogram": [
                      {
                        "bin_start": 1.5,
                        "bin_end": 1.6,
                        "count": 0
                      },
                      {
                        "bin_start": 1.6,
                        "bin_end": 1.7,
                        "count": 0
                      },
                      {
                        "bin_start": 1.7,
                        "bin_end": 1.8,
                        "count": 0
                      },
                      {
                        "bin_start": 1.8,
                        "bin_end": 1.9,
                        "count": 0
                      },
                      {
                        "bin_start": 1.9,
                        "bin_end": 2,
                        "count": 0
                      },
                      {
                        "bin_start": 2,
                        "bin_end": 2.1,
                        "count": 1
                      },
                      {
                        "bin_start": 2.1,
                        "bin_end": 2.2,
                        "count": 0
                      },
                      {
                        "bin_start": 2.2,
                        "bin_end": 2.3,
                        "count": 0
                      },
                      {
                        "bin_start": 2.3,
                        "bin_end": 2.4,
                        "count": 0
                      },
                      {
                        "bin_start": 2.4,
                        "bin_end": 2.5,
                        "count": 0
                      }
                    ]
                  }
                },
                {
                  "name": "EMA_slope_15",
                  "dtype": "float64",
                  "stats": {
                    "unique_count": 1,
                    "nan_count": 0,
                    "min": "0.3689512431847106",
                    "max": "0.3689512431847106",
                    "histogram": [
                      {
                        "bin_start": -0.13104875681528938,
                        "bin_end": -0.031048756815289374,
                        "count": 0
                      },
                      {
                        "bin_start": -0.031048756815289374,
                        "bin_end": 0.06895124318471063,
                        "count": 0
                      },
                      {
                        "bin_start": 0.06895124318471063,
                        "bin_end": 0.16895124318471066,
                        "count": 0
                      },
                      {
                        "bin_start": 0.16895124318471066,
                        "bin_end": 0.26895124318471064,
                        "count": 0
                      },
                      {
                        "bin_start": 0.26895124318471064,
                        "bin_end": 0.3689512431847106,
                        "count": 0
                      },
                      {
                        "bin_start": 0.3689512431847106,
                        "bin_end": 0.4689512431847107,
                        "count": 1
                      },
                      {
                        "bin_start": 0.4689512431847107,
                        "bin_end": 0.5689512431847107,
                        "count": 0
                      },
                      {
                        "bin_start": 0.5689512431847107,
                        "bin_end": 0.6689512431847107,
                        "count": 0
                      },
                      {
                        "bin_start": 0.6689512431847107,
                        "bin_end": 0.7689512431847106,
                        "count": 0
                      },
                      {
                        "bin_start": 0.7689512431847106,
                        "bin_end": 0.8689512431847106,
                        "count": 0
                      }
                    ]
                  }
                },
                {
                  "name": "EMA_slope",
                  "dtype": "float64",
                  "stats": {
                    "unique_count": 1,
                    "nan_count": 0,
                    "min": "1.213316027118708",
                    "max": "1.213316027118708",
                    "histogram": [
                      {
                        "bin_start": 0.713316027118708,
                        "bin_end": 0.813316027118708,
                        "count": 0
                      },
                      {
                        "bin_start": 0.813316027118708,
                        "bin_end": 0.913316027118708,
                        "count": 0
                      },
                      {
                        "bin_start": 0.913316027118708,
                        "bin_end": 1.013316027118708,
                        "count": 0
                      },
                      {
                        "bin_start": 1.013316027118708,
                        "bin_end": 1.113316027118708,
                        "count": 0
                      },
                      {
                        "bin_start": 1.113316027118708,
                        "bin_end": 1.213316027118708,
                        "count": 0
                      },
                      {
                        "bin_start": 1.213316027118708,
                        "bin_end": 1.313316027118708,
                        "count": 1
                      },
                      {
                        "bin_start": 1.313316027118708,
                        "bin_end": 1.4133160271187082,
                        "count": 0
                      },
                      {
                        "bin_start": 1.4133160271187082,
                        "bin_end": 1.513316027118708,
                        "count": 0
                      },
                      {
                        "bin_start": 1.513316027118708,
                        "bin_end": 1.613316027118708,
                        "count": 0
                      },
                      {
                        "bin_start": 1.613316027118708,
                        "bin_end": 1.713316027118708,
                        "count": 0
                      }
                    ]
                  }
                },
                {
                  "name": "bullish_1",
                  "dtype": "float64",
                  "stats": {
                    "unique_count": 1,
                    "nan_count": 0,
                    "min": "0.7105494737625122",
                    "max": "0.7105494737625122",
                    "histogram": [
                      {
                        "bin_start": 0.2105494737625122,
                        "bin_end": 0.3105494737625122,
                        "count": 0
                      },
                      {
                        "bin_start": 0.3105494737625122,
                        "bin_end": 0.4105494737625122,
                        "count": 0
                      },
                      {
                        "bin_start": 0.4105494737625122,
                        "bin_end": 0.5105494737625123,
                        "count": 0
                      },
                      {
                        "bin_start": 0.5105494737625123,
                        "bin_end": 0.6105494737625122,
                        "count": 0
                      },
                      {
                        "bin_start": 0.6105494737625122,
                        "bin_end": 0.7105494737625122,
                        "count": 0
                      },
                      {
                        "bin_start": 0.7105494737625122,
                        "bin_end": 0.8105494737625123,
                        "count": 1
                      },
                      {
                        "bin_start": 0.8105494737625123,
                        "bin_end": 0.9105494737625123,
                        "count": 0
                      },
                      {
                        "bin_start": 0.9105494737625123,
                        "bin_end": 1.0105494737625123,
                        "count": 0
                      },
                      {
                        "bin_start": 1.0105494737625123,
                        "bin_end": 1.1105494737625121,
                        "count": 0
                      },
                      {
                        "bin_start": 1.1105494737625121,
                        "bin_end": 1.2105494737625122,
                        "count": 0
                      }
                    ]
                  }
                },
                {
                  "name": "volume",
                  "dtype": "int64",
                  "stats": {
                    "unique_count": 1,
                    "nan_count": 0,
                    "min": "1343",
                    "max": "1343",
                    "histogram": [
                      {
                        "bin_start": 1342.5,
                        "bin_end": 1342.6,
                        "count": 0
                      },
                      {
                        "bin_start": 1342.6,
                        "bin_end": 1342.7,
                        "count": 0
                      },
                      {
                        "bin_start": 1342.7,
                        "bin_end": 1342.8,
                        "count": 0
                      },
                      {
                        "bin_start": 1342.8,
                        "bin_end": 1342.9,
                        "count": 0
                      },
                      {
                        "bin_start": 1342.9,
                        "bin_end": 1343,
                        "count": 0
                      },
                      {
                        "bin_start": 1343,
                        "bin_end": 1343.1,
                        "count": 1
                      },
                      {
                        "bin_start": 1343.1,
                        "bin_end": 1343.2,
                        "count": 0
                      },
                      {
                        "bin_start": 1343.2,
                        "bin_end": 1343.3,
                        "count": 0
                      },
                      {
                        "bin_start": 1343.3,
                        "bin_end": 1343.4,
                        "count": 0
                      },
                      {
                        "bin_start": 1343.4,
                        "bin_end": 1343.5,
                        "count": 0
                      }
                    ]
                  }
                },
                {
                  "name": "move_from_bottom",
                  "dtype": "float64",
                  "stats": {
                    "unique_count": 1,
                    "nan_count": 0,
                    "min": "0.3230044892149508",
                    "max": "0.3230044892149508",
                    "histogram": [
                      {
                        "bin_start": -0.17699551078504921,
                        "bin_end": -0.07699551078504921,
                        "count": 0
                      },
                      {
                        "bin_start": -0.07699551078504921,
                        "bin_end": 0.023004489214950796,
                        "count": 0
                      },
                      {
                        "bin_start": 0.023004489214950796,
                        "bin_end": 0.12300448921495083,
                        "count": 0
                      },
                      {
                        "bin_start": 0.12300448921495083,
                        "bin_end": 0.2230044892149508,
                        "count": 0
                      },
                      {
                        "bin_start": 0.2230044892149508,
                        "bin_end": 0.3230044892149508,
                        "count": 0
                      },
                      {
                        "bin_start": 0.3230044892149508,
                        "bin_end": 0.4230044892149509,
                        "count": 1
                      },
                      {
                        "bin_start": 0.4230044892149509,
                        "bin_end": 0.5230044892149508,
                        "count": 0
                      },
                      {
                        "bin_start": 0.5230044892149508,
                        "bin_end": 0.6230044892149509,
                        "count": 0
                      },
                      {
                        "bin_start": 0.6230044892149509,
                        "bin_end": 0.7230044892149508,
                        "count": 0
                      },
                      {
                        "bin_start": 0.7230044892149508,
                        "bin_end": 0.8230044892149508,
                        "count": 0
                      }
                    ]
                  }
                },
                {
                  "name": "_deepnote_index_column",
                  "dtype": "int64"
                }
              ],
              "rows": [
                {
                  "datetime": "2025-04-04 18:15:00+00:00",
                  "y_true": 2,
                  "EMA_slope_15": 0.3689512431847106,
                  "EMA_slope": 1.213316027118708,
                  "bullish_1": 0.7105494737625122,
                  "volume": 1343,
                  "move_from_bottom": 0.3230044892149508,
                  "_deepnote_index_column": 4343
                }
              ],
              "type": "dataframe"
            },
            "text/plain": "                       datetime  y_true  EMA_slope_15  EMA_slope  bullish_1  \\\n4343  2025-04-04 18:15:00+00:00       2      0.368951   1.213316   0.710549   \n\n      volume  move_from_bottom  \n4343    1343          0.323004  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>datetime</th>\n      <th>y_true</th>\n      <th>EMA_slope_15</th>\n      <th>EMA_slope</th>\n      <th>bullish_1</th>\n      <th>volume</th>\n      <th>move_from_bottom</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4343</th>\n      <td>2025-04-04 18:15:00+00:00</td>\n      <td>2</td>\n      <td>0.368951</td>\n      <td>1.213316</td>\n      <td>0.710549</td>\n      <td>1343</td>\n      <td>0.323004</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "d3353fed",
        "execution_start": 1743761649827,
        "execution_millis": 5,
        "execution_context_id": "7cb1b84d-18b8-45a4-8eed-91ba91512a0a",
        "cell_id": "58296929aa1542799f7a2df1949e7ea2",
        "deepnote_cell_type": "code"
      },
      "source": "base_data[(base_data['volume']> 600)\n        & (base_data['bullish_1']> 0.8)\n        & ((base_data['EMA_slope_15']>0.25) | (base_data['EMA_slope_15']<-0.25))\n        & (base_data['move_from_bottom']>0.15) #& (base_data['move_from_bottom']<0.25) \n]['y_true'].value_counts()",
      "block_group": "04aa8b4a06b043299e38fe2d1b44a6e5",
      "execution_count": 457,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 457,
          "data": {
            "text/plain": "y_true\n2    874\n1    839\n3    503\n0    226\nName: count, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "802284fb",
        "execution_start": 1743712925395,
        "execution_millis": 1,
        "execution_context_id": "7cb1b84d-18b8-45a4-8eed-91ba91512a0a",
        "cell_id": "30aff1d9819a4fc580618d4a8195d983",
        "deepnote_cell_type": "code"
      },
      "source": "(predicted[1] * 3000) - ((predicted[0]+predicted[2]+predicted[3])*1000)",
      "block_group": "e297c84a72f6436e924f8a1a3bfcccdd",
      "execution_count": 355,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 355,
          "data": {
            "text/plain": "951000"
          },
          "metadata": {}
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "a76cc029",
        "execution_start": 1743799866015,
        "execution_millis": 0,
        "execution_context_id": "7cb1b84d-18b8-45a4-8eed-91ba91512a0a",
        "cell_id": "fbad4bbe25514ef3807324a7db7248e2",
        "deepnote_cell_type": "code"
      },
      "source": "history[(history['bearish_2']> 0.7)\n        #(history['volume']> 600)\n        \n        #& ((history['EMA_slope']>0.25) | (history['EMA_slope']<-0.25))\n        #& (history['move_from_top']<0.45) & (history['move_from_top']>0.12)\n]['y_true'].value_counts()",
      "block_group": "093eaeda697b478a835173389f04fdc7",
      "execution_count": 541,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 541,
          "data": {
            "text/plain": "y_true\n3    1\nName: count, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "8325fc33",
        "execution_start": 1743759888415,
        "execution_millis": 1,
        "execution_context_id": "7cb1b84d-18b8-45a4-8eed-91ba91512a0a",
        "cell_id": "37df0769b2f34b7082380408100ba4cb",
        "deepnote_cell_type": "code"
      },
      "source": "base_data[(base_data['volume']> 600)\n        & (base_data['bearish_2']> 0.72)\n        & ((base_data['EMA_slope_15']>0.25) | (base_data['EMA_slope_15']<-0.25))\n        #& (base_data['move_from_top']<0.35) & (base_data['move_from_top']>0.12)\n]['y_true'].value_counts()\n#predicted",
      "block_group": "45eb03608b2645f49125849b3b647e50",
      "execution_count": 442,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 442,
          "data": {
            "text/plain": "y_true\n2    2660\n1    2491\n3    1288\n0    1005\nName: count, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "c514a058",
        "execution_start": 1743712576745,
        "execution_millis": 1,
        "execution_context_id": "7cb1b84d-18b8-45a4-8eed-91ba91512a0a",
        "cell_id": "5451d5629d6f4642b518bb06b6656cbb",
        "deepnote_cell_type": "code"
      },
      "source": "history[(history['volume']> 700)\n        & (history['bearish_2']> 0.72)\n        & ((history['EMA_slope_15']>0.25) | (history['EMA_slope_15']<-0.25))\n        & (history['move_from_top']<0.45) & (history['move_from_top']>0.15)\n]['y_true'].value_counts()",
      "block_group": "4e4eaa49dcc24affabea1ee65ff6a11a",
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 333,
          "data": {
            "text/plain": "y_true\n1    3\n3    2\n2    2\n0    1\nName: count, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "482761d0607f4f15a1f20b26b33369d9",
        "deepnote_cell_type": "code"
      },
      "source": "",
      "block_group": "2479e57d3eaa409c920d9087fcfa596e",
      "execution_count": null,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=a127aa9e-0a77-4af9-a6ce-85e7a9b74042' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "deepnote_persisted_session": {
      "createdAt": "2025-04-04T23:52:26.202Z"
    },
    "deepnote_notebook_id": "71be41e3a1bd47e492397d4541c4b935"
  }
}